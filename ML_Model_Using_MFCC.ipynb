{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6a9c1266-020c-4b04-8b1b-1674b7b9d5d4",
   "metadata": {},
   "source": [
    "### Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4b970128-f129-4931-8aa8-d6b917b819b6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import librosa\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pydub import AudioSegment\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns\n",
    "sns.set_style('darkgrid')\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Bidirectional, LSTM, Dense"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec397a6e-f402-4fe9-b33e-633d2e920030",
   "metadata": {},
   "source": [
    "### Extract MFCC features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4e8cdc2d-2df0-4834-bbec-05413f2dbde9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define function to extract MFCC features from audio files\n",
    "def extract_mfcc_features(file_path):\n",
    "    audio, sample_rate = librosa.load(file_path, res_type='kaiser_fast')\n",
    "    mfccs = librosa.feature.mfcc(y=audio, sr=sample_rate, n_mfcc=40)\n",
    "    mfccs = np.mean(mfccs.T,axis=0)\n",
    "    return mfccs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a64c134b-68a4-4291-beb3-049cc42cad9f",
   "metadata": {},
   "source": [
    "### Extracting MFCC features from the Actual data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d51fc41a-df6b-4e14-8697-4fd945772cb6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "107\n",
      "108\n",
      "109\n",
      "110\n",
      "111\n",
      "112\n",
      "113\n",
      "114\n",
      "115\n",
      "116\n",
      "117\n",
      "118\n",
      "119\n",
      "120\n",
      "121\n",
      "122\n",
      "123\n",
      "124\n",
      "125\n",
      "126\n",
      "127\n",
      "128\n",
      "129\n",
      "130\n",
      "131\n",
      "132\n"
     ]
    }
   ],
   "source": [
    "# Load audio files and extract MFCC features\n",
    "X_mfcc_132 = []\n",
    "y_mfcc_132 = []\n",
    "i=1\n",
    "level_path_132 = [\"C:\\\\Users\\\\SSN\\\\E-DAIC1\\\\Phase2\\\\Nonstress\\\\No\", \n",
    "              \"C:\\\\Users\\\\SSN\\\\E-DAIC1\\\\Phase2\\\\Nonstress\\\\Mild\",\n",
    "              \"C:\\\\Users\\\\SSN\\\\E-DAIC1\\\\Phase2\\\\Stress\\\\Moderate\",\n",
    "              \"C:\\\\Users\\\\SSN\\\\E-DAIC1\\\\Phase2\\\\Stress\\\\Severe\",\n",
    "              \"C:\\\\Users\\\\SSN\\\\E-DAIC1\\\\Phase2\\\\Stress\\\\Extreme\"]\n",
    "\n",
    "for level in level_path_132:\n",
    "    for file in os.listdir(level):\n",
    "        if file.startswith(\"Nonstress\") or file.startswith(\"Stress\"):\n",
    "            file_path = os.path.join(level, file)\n",
    "            # print(file_path)\n",
    "            mfcc = extract_mfcc_features(file_path)\n",
    "            X_mfcc_132.append(mfcc)\n",
    "            y_mfcc_132.append(level.split(\"\\\\\")[-2])\n",
    "\n",
    "            print(i)\n",
    "            i+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93017221-76e9-4f37-bdb5-f6e24cf036eb",
   "metadata": {},
   "source": [
    "### Extracting MFCC features from the Augmented data(Noise added data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c77f7717-e9a9-4c3c-beda-cf6917e533a8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "107\n",
      "108\n",
      "109\n",
      "110\n",
      "111\n",
      "112\n",
      "113\n",
      "114\n",
      "115\n",
      "116\n",
      "117\n",
      "118\n",
      "119\n",
      "120\n",
      "121\n",
      "122\n",
      "123\n",
      "124\n",
      "125\n",
      "126\n",
      "127\n",
      "128\n",
      "129\n",
      "130\n",
      "131\n",
      "132\n"
     ]
    }
   ],
   "source": [
    "# Load audio files and extract MFCC features\n",
    "X_A_mfcc_132 = []\n",
    "y_A_mfcc_132 = []\n",
    "i=1\n",
    "level_path_132 = [\"C:\\\\Users\\\\SSN\\\\E-DAIC1\\\\Phase2\\\\Nonstress\\\\No\", \n",
    "              \"C:\\\\Users\\\\SSN\\\\E-DAIC1\\\\Phase2\\\\Nonstress\\\\Mild\",\n",
    "              \"C:\\\\Users\\\\SSN\\\\E-DAIC1\\\\Phase2\\\\Stress\\\\Moderate\",\n",
    "              \"C:\\\\Users\\\\SSN\\\\E-DAIC1\\\\Phase2\\\\Stress\\\\Severe\",\n",
    "              \"C:\\\\Users\\\\SSN\\\\E-DAIC1\\\\Phase2\\\\Stress\\\\Extreme\"]\n",
    "\n",
    "for level in level_path_132:\n",
    "    for file in os.listdir(level):\n",
    "        if file.startswith(\"A_Nonstress\") or file.startswith(\"A_Stress\"):\n",
    "            file_path = os.path.join(level, file)\n",
    "            # print(file_path)\n",
    "            mfcc = extract_mfcc_features(file_path)\n",
    "            X_A_mfcc_132.append(mfcc)\n",
    "            y_A_mfcc_132.append(level.split(\"\\\\\")[-2])\n",
    "\n",
    "            print(i)\n",
    "            i+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8520bda1-35ed-45db-aa57-9dc6bba36d5c",
   "metadata": {},
   "source": [
    "### Extracting MFCC features from the Splitted Actual data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d4644b31-ceba-419b-a9c9-cb701af20dcc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "107\n",
      "108\n",
      "109\n",
      "110\n",
      "111\n",
      "112\n",
      "113\n",
      "114\n",
      "115\n",
      "116\n",
      "117\n",
      "118\n",
      "119\n",
      "120\n",
      "121\n",
      "122\n",
      "123\n",
      "124\n",
      "125\n",
      "126\n",
      "127\n",
      "128\n",
      "129\n",
      "130\n",
      "131\n",
      "132\n",
      "133\n",
      "134\n",
      "135\n",
      "136\n",
      "137\n",
      "138\n",
      "139\n",
      "140\n",
      "141\n",
      "142\n",
      "143\n",
      "144\n",
      "145\n",
      "146\n",
      "147\n",
      "148\n",
      "149\n",
      "150\n",
      "151\n",
      "152\n",
      "153\n",
      "154\n",
      "155\n",
      "156\n",
      "157\n",
      "158\n",
      "159\n",
      "160\n",
      "161\n",
      "162\n",
      "163\n",
      "164\n",
      "165\n",
      "166\n",
      "167\n",
      "168\n",
      "169\n",
      "170\n",
      "171\n",
      "172\n",
      "173\n",
      "174\n",
      "175\n",
      "176\n",
      "177\n",
      "178\n",
      "179\n",
      "180\n",
      "181\n",
      "182\n",
      "183\n",
      "184\n",
      "185\n",
      "186\n",
      "187\n",
      "188\n",
      "189\n",
      "190\n",
      "191\n",
      "192\n",
      "193\n",
      "194\n",
      "195\n",
      "196\n",
      "197\n",
      "198\n",
      "199\n",
      "200\n",
      "201\n",
      "202\n",
      "203\n",
      "204\n",
      "205\n",
      "206\n",
      "207\n",
      "208\n",
      "209\n",
      "210\n",
      "211\n",
      "212\n",
      "213\n",
      "214\n",
      "215\n",
      "216\n",
      "217\n",
      "218\n",
      "219\n",
      "220\n",
      "221\n",
      "222\n",
      "223\n",
      "224\n",
      "225\n",
      "226\n",
      "227\n",
      "228\n",
      "229\n",
      "230\n",
      "231\n",
      "232\n",
      "233\n",
      "234\n",
      "235\n",
      "236\n",
      "237\n",
      "238\n",
      "239\n",
      "240\n",
      "241\n",
      "242\n",
      "243\n",
      "244\n",
      "245\n",
      "246\n",
      "247\n",
      "248\n",
      "249\n",
      "250\n",
      "251\n",
      "252\n",
      "253\n",
      "254\n",
      "255\n",
      "256\n",
      "257\n",
      "258\n",
      "259\n",
      "260\n",
      "261\n",
      "262\n",
      "263\n",
      "264\n",
      "265\n",
      "266\n",
      "267\n",
      "268\n",
      "269\n",
      "270\n",
      "271\n",
      "272\n",
      "273\n",
      "274\n",
      "275\n",
      "276\n",
      "277\n",
      "278\n",
      "279\n",
      "280\n",
      "281\n",
      "282\n",
      "283\n",
      "284\n",
      "285\n",
      "286\n",
      "287\n",
      "288\n",
      "289\n",
      "290\n",
      "291\n",
      "292\n",
      "293\n",
      "294\n",
      "295\n",
      "296\n",
      "297\n",
      "298\n",
      "299\n",
      "300\n",
      "301\n",
      "302\n",
      "303\n",
      "304\n",
      "305\n",
      "306\n",
      "307\n",
      "308\n",
      "309\n",
      "310\n",
      "311\n",
      "312\n",
      "313\n",
      "314\n",
      "315\n",
      "316\n",
      "317\n",
      "318\n",
      "319\n",
      "320\n",
      "321\n",
      "322\n",
      "323\n",
      "324\n",
      "325\n",
      "326\n",
      "327\n",
      "328\n",
      "329\n",
      "330\n",
      "331\n",
      "332\n",
      "333\n",
      "334\n",
      "335\n",
      "336\n",
      "337\n",
      "338\n",
      "339\n",
      "340\n",
      "341\n",
      "342\n",
      "343\n",
      "344\n",
      "345\n",
      "346\n",
      "347\n",
      "348\n",
      "349\n",
      "350\n",
      "351\n",
      "352\n",
      "353\n",
      "354\n",
      "355\n",
      "356\n",
      "357\n",
      "358\n",
      "359\n",
      "360\n",
      "361\n",
      "362\n",
      "363\n",
      "364\n",
      "365\n",
      "366\n",
      "367\n",
      "368\n",
      "369\n",
      "370\n",
      "371\n",
      "372\n",
      "373\n",
      "374\n",
      "375\n",
      "376\n",
      "377\n",
      "378\n",
      "379\n",
      "380\n",
      "381\n",
      "382\n",
      "383\n",
      "384\n",
      "385\n",
      "386\n",
      "387\n",
      "388\n",
      "389\n",
      "390\n",
      "391\n",
      "392\n",
      "393\n",
      "394\n",
      "395\n",
      "396\n",
      "397\n",
      "398\n",
      "399\n",
      "400\n",
      "401\n",
      "402\n",
      "403\n",
      "404\n",
      "405\n",
      "406\n",
      "407\n",
      "408\n",
      "409\n",
      "410\n",
      "411\n",
      "412\n",
      "413\n",
      "414\n",
      "415\n",
      "416\n",
      "417\n",
      "418\n",
      "419\n",
      "420\n",
      "421\n",
      "422\n",
      "423\n",
      "424\n",
      "425\n",
      "426\n",
      "427\n",
      "428\n",
      "429\n",
      "430\n",
      "431\n",
      "432\n",
      "433\n",
      "434\n",
      "435\n",
      "436\n",
      "437\n",
      "438\n",
      "439\n",
      "440\n",
      "441\n",
      "442\n",
      "443\n",
      "444\n",
      "445\n",
      "446\n",
      "447\n",
      "448\n",
      "449\n",
      "450\n",
      "451\n",
      "452\n",
      "453\n",
      "454\n",
      "455\n",
      "456\n",
      "457\n",
      "458\n",
      "459\n",
      "460\n",
      "461\n",
      "462\n",
      "463\n",
      "464\n",
      "465\n",
      "466\n",
      "467\n",
      "468\n",
      "469\n",
      "470\n",
      "471\n",
      "472\n",
      "473\n",
      "474\n",
      "475\n",
      "476\n",
      "477\n",
      "478\n",
      "479\n",
      "480\n",
      "481\n",
      "482\n",
      "483\n",
      "484\n",
      "485\n",
      "486\n",
      "487\n",
      "488\n",
      "489\n",
      "490\n",
      "491\n",
      "492\n",
      "493\n",
      "494\n",
      "495\n",
      "496\n",
      "497\n",
      "498\n",
      "499\n",
      "500\n",
      "501\n",
      "502\n",
      "503\n",
      "504\n",
      "505\n",
      "506\n",
      "507\n",
      "508\n",
      "509\n",
      "510\n",
      "511\n",
      "512\n",
      "513\n",
      "514\n",
      "515\n",
      "516\n",
      "517\n",
      "518\n",
      "519\n",
      "520\n",
      "521\n",
      "522\n",
      "523\n",
      "524\n",
      "525\n",
      "526\n",
      "527\n",
      "528\n",
      "529\n",
      "530\n",
      "531\n",
      "532\n",
      "533\n",
      "534\n",
      "535\n",
      "536\n",
      "537\n",
      "538\n",
      "539\n",
      "540\n",
      "541\n",
      "542\n",
      "543\n",
      "544\n",
      "545\n",
      "546\n",
      "547\n",
      "548\n",
      "549\n",
      "550\n",
      "551\n",
      "552\n",
      "553\n",
      "554\n",
      "555\n",
      "556\n",
      "557\n",
      "558\n",
      "559\n",
      "560\n",
      "561\n",
      "562\n",
      "563\n",
      "564\n",
      "565\n",
      "566\n",
      "567\n",
      "568\n",
      "569\n",
      "570\n",
      "571\n",
      "572\n",
      "573\n",
      "574\n",
      "575\n",
      "576\n",
      "577\n",
      "578\n",
      "579\n",
      "580\n",
      "581\n",
      "582\n",
      "583\n",
      "584\n",
      "585\n",
      "586\n",
      "587\n",
      "588\n",
      "589\n",
      "590\n",
      "591\n",
      "592\n",
      "593\n",
      "594\n",
      "595\n",
      "596\n",
      "597\n",
      "598\n",
      "599\n",
      "600\n",
      "601\n",
      "602\n",
      "603\n",
      "604\n",
      "605\n",
      "606\n",
      "607\n",
      "608\n",
      "609\n",
      "610\n",
      "611\n",
      "612\n",
      "613\n",
      "614\n",
      "615\n",
      "616\n",
      "617\n",
      "618\n",
      "619\n",
      "620\n",
      "621\n",
      "622\n",
      "623\n",
      "624\n",
      "625\n",
      "626\n",
      "627\n",
      "628\n",
      "629\n",
      "630\n",
      "631\n",
      "632\n",
      "633\n",
      "634\n",
      "635\n",
      "636\n",
      "637\n",
      "638\n",
      "639\n",
      "640\n",
      "641\n",
      "642\n",
      "643\n",
      "644\n",
      "645\n",
      "646\n",
      "647\n",
      "648\n",
      "649\n",
      "650\n",
      "651\n",
      "652\n",
      "653\n",
      "654\n",
      "655\n",
      "656\n",
      "657\n",
      "658\n",
      "659\n",
      "660\n",
      "661\n",
      "662\n",
      "663\n",
      "664\n",
      "665\n",
      "666\n",
      "667\n",
      "668\n",
      "669\n",
      "670\n",
      "671\n",
      "672\n",
      "673\n",
      "674\n",
      "675\n",
      "676\n",
      "677\n",
      "678\n",
      "679\n",
      "680\n",
      "681\n",
      "682\n",
      "683\n",
      "684\n",
      "685\n",
      "686\n",
      "687\n",
      "688\n",
      "689\n",
      "690\n",
      "691\n",
      "692\n",
      "693\n",
      "694\n",
      "695\n",
      "696\n",
      "697\n",
      "698\n",
      "699\n",
      "700\n",
      "701\n",
      "702\n",
      "703\n",
      "704\n",
      "705\n",
      "706\n",
      "707\n",
      "708\n",
      "709\n",
      "710\n",
      "711\n",
      "712\n",
      "713\n",
      "714\n",
      "715\n",
      "716\n",
      "717\n",
      "718\n",
      "719\n",
      "720\n",
      "721\n",
      "722\n",
      "723\n",
      "724\n",
      "725\n",
      "726\n",
      "727\n",
      "728\n",
      "729\n",
      "730\n",
      "731\n",
      "732\n",
      "733\n",
      "734\n",
      "735\n",
      "736\n",
      "737\n",
      "738\n",
      "739\n",
      "740\n",
      "741\n",
      "742\n",
      "743\n",
      "744\n",
      "745\n",
      "746\n",
      "747\n",
      "748\n",
      "749\n",
      "750\n",
      "751\n",
      "752\n",
      "753\n",
      "754\n",
      "755\n",
      "756\n",
      "757\n",
      "758\n",
      "759\n",
      "760\n",
      "761\n",
      "762\n",
      "763\n",
      "764\n",
      "765\n",
      "766\n",
      "767\n",
      "768\n",
      "769\n",
      "770\n",
      "771\n",
      "772\n",
      "773\n",
      "774\n",
      "775\n",
      "776\n",
      "777\n",
      "778\n",
      "779\n",
      "780\n",
      "781\n",
      "782\n",
      "783\n",
      "784\n",
      "785\n",
      "786\n",
      "787\n",
      "788\n",
      "789\n",
      "790\n",
      "791\n",
      "792\n",
      "793\n",
      "794\n",
      "795\n",
      "796\n",
      "797\n",
      "798\n",
      "799\n",
      "800\n",
      "801\n",
      "802\n",
      "803\n",
      "804\n",
      "805\n",
      "806\n",
      "807\n",
      "808\n",
      "809\n",
      "810\n",
      "811\n",
      "812\n",
      "813\n",
      "814\n",
      "815\n",
      "816\n",
      "817\n",
      "818\n",
      "819\n",
      "820\n",
      "821\n",
      "822\n",
      "823\n",
      "824\n",
      "825\n",
      "826\n",
      "827\n",
      "828\n",
      "829\n",
      "830\n",
      "831\n",
      "832\n",
      "833\n",
      "834\n",
      "835\n",
      "836\n",
      "837\n",
      "838\n",
      "839\n",
      "840\n",
      "841\n",
      "842\n",
      "843\n",
      "844\n",
      "845\n",
      "846\n",
      "847\n",
      "848\n",
      "849\n",
      "850\n",
      "851\n",
      "852\n",
      "853\n",
      "854\n",
      "855\n",
      "856\n",
      "857\n",
      "858\n",
      "859\n",
      "860\n",
      "861\n",
      "862\n",
      "863\n",
      "864\n",
      "865\n",
      "866\n",
      "867\n",
      "868\n",
      "869\n",
      "870\n",
      "871\n",
      "872\n",
      "873\n",
      "874\n",
      "875\n",
      "876\n",
      "877\n",
      "878\n",
      "879\n",
      "880\n",
      "881\n",
      "882\n",
      "883\n",
      "884\n",
      "885\n",
      "886\n",
      "887\n",
      "888\n",
      "889\n",
      "890\n",
      "891\n",
      "892\n",
      "893\n",
      "894\n",
      "895\n",
      "896\n",
      "897\n",
      "898\n",
      "899\n",
      "900\n",
      "901\n",
      "902\n",
      "903\n",
      "904\n",
      "905\n",
      "906\n",
      "907\n",
      "908\n",
      "909\n",
      "910\n",
      "911\n",
      "912\n",
      "913\n",
      "914\n",
      "915\n",
      "916\n",
      "917\n",
      "918\n",
      "919\n",
      "920\n",
      "921\n",
      "922\n",
      "923\n",
      "924\n",
      "925\n",
      "926\n",
      "927\n",
      "928\n",
      "929\n",
      "930\n",
      "931\n",
      "932\n",
      "933\n",
      "934\n",
      "935\n",
      "936\n",
      "937\n",
      "938\n",
      "939\n",
      "940\n",
      "941\n",
      "942\n",
      "943\n",
      "944\n",
      "945\n",
      "946\n",
      "947\n",
      "948\n",
      "949\n",
      "950\n",
      "951\n",
      "952\n",
      "953\n",
      "954\n",
      "955\n",
      "956\n",
      "957\n",
      "958\n",
      "959\n",
      "960\n",
      "961\n",
      "962\n",
      "963\n",
      "964\n",
      "965\n",
      "966\n",
      "967\n",
      "968\n",
      "969\n",
      "970\n",
      "971\n",
      "972\n",
      "973\n",
      "974\n",
      "975\n",
      "976\n",
      "977\n",
      "978\n",
      "979\n",
      "980\n",
      "981\n",
      "982\n",
      "983\n",
      "984\n",
      "985\n",
      "986\n",
      "987\n",
      "988\n",
      "989\n",
      "990\n",
      "991\n",
      "992\n",
      "993\n",
      "994\n",
      "995\n",
      "996\n",
      "997\n",
      "998\n",
      "999\n",
      "1000\n",
      "1001\n",
      "1002\n",
      "1003\n",
      "1004\n",
      "1005\n",
      "1006\n",
      "1007\n",
      "1008\n",
      "1009\n",
      "1010\n",
      "1011\n",
      "1012\n",
      "1013\n",
      "1014\n",
      "1015\n",
      "1016\n",
      "1017\n",
      "1018\n",
      "1019\n",
      "1020\n",
      "1021\n",
      "1022\n",
      "1023\n",
      "1024\n",
      "1025\n",
      "1026\n",
      "1027\n",
      "1028\n",
      "1029\n",
      "1030\n",
      "1031\n",
      "1032\n",
      "1033\n",
      "1034\n",
      "1035\n",
      "1036\n",
      "1037\n",
      "1038\n",
      "1039\n",
      "1040\n",
      "1041\n",
      "1042\n",
      "1043\n",
      "1044\n",
      "1045\n",
      "1046\n",
      "1047\n",
      "1048\n",
      "1049\n",
      "1050\n",
      "1051\n",
      "1052\n",
      "1053\n",
      "1054\n",
      "1055\n",
      "1056\n",
      "1057\n",
      "1058\n",
      "1059\n",
      "1060\n",
      "1061\n",
      "1062\n",
      "1063\n",
      "1064\n",
      "1065\n",
      "1066\n",
      "1067\n",
      "1068\n",
      "1069\n",
      "1070\n",
      "1071\n",
      "1072\n",
      "1073\n",
      "1074\n",
      "1075\n",
      "1076\n",
      "1077\n",
      "1078\n",
      "1079\n",
      "1080\n",
      "1081\n",
      "1082\n",
      "1083\n",
      "1084\n",
      "1085\n",
      "1086\n",
      "1087\n",
      "1088\n",
      "1089\n",
      "1090\n",
      "1091\n",
      "1092\n",
      "1093\n",
      "1094\n",
      "1095\n",
      "1096\n",
      "1097\n",
      "1098\n",
      "1099\n",
      "1100\n",
      "1101\n",
      "1102\n",
      "1103\n",
      "1104\n",
      "1105\n",
      "1106\n",
      "1107\n",
      "1108\n",
      "1109\n",
      "1110\n",
      "1111\n",
      "1112\n",
      "1113\n",
      "1114\n",
      "1115\n",
      "1116\n",
      "1117\n",
      "1118\n",
      "1119\n",
      "1120\n",
      "1121\n",
      "1122\n",
      "1123\n",
      "1124\n",
      "1125\n",
      "1126\n",
      "1127\n",
      "1128\n",
      "1129\n",
      "1130\n",
      "1131\n",
      "1132\n",
      "1133\n",
      "1134\n",
      "1135\n",
      "1136\n",
      "1137\n",
      "1138\n",
      "1139\n",
      "1140\n",
      "1141\n",
      "1142\n",
      "1143\n",
      "1144\n",
      "1145\n",
      "1146\n",
      "1147\n",
      "1148\n",
      "1149\n",
      "1150\n",
      "1151\n",
      "1152\n",
      "1153\n",
      "1154\n",
      "1155\n",
      "1156\n",
      "1157\n",
      "1158\n",
      "1159\n",
      "1160\n",
      "1161\n",
      "1162\n",
      "1163\n",
      "1164\n",
      "1165\n",
      "1166\n",
      "1167\n",
      "1168\n",
      "1169\n",
      "1170\n",
      "1171\n",
      "1172\n",
      "1173\n",
      "1174\n",
      "1175\n",
      "1176\n",
      "1177\n",
      "1178\n",
      "1179\n",
      "1180\n",
      "1181\n",
      "1182\n",
      "1183\n",
      "1184\n",
      "1185\n",
      "1186\n",
      "1187\n",
      "1188\n",
      "1189\n",
      "1190\n",
      "1191\n",
      "1192\n",
      "1193\n",
      "1194\n",
      "1195\n",
      "1196\n",
      "1197\n",
      "1198\n",
      "1199\n",
      "1200\n",
      "1201\n",
      "1202\n",
      "1203\n",
      "1204\n",
      "1205\n",
      "1206\n",
      "1207\n",
      "1208\n",
      "1209\n",
      "1210\n",
      "1211\n",
      "1212\n",
      "1213\n",
      "1214\n",
      "1215\n",
      "1216\n",
      "1217\n",
      "1218\n",
      "1219\n",
      "1220\n",
      "1221\n",
      "1222\n",
      "1223\n",
      "1224\n",
      "1225\n",
      "1226\n",
      "1227\n",
      "1228\n",
      "1229\n",
      "1230\n",
      "1231\n",
      "1232\n",
      "1233\n",
      "1234\n",
      "1235\n",
      "1236\n",
      "1237\n",
      "1238\n",
      "1239\n",
      "1240\n",
      "1241\n",
      "1242\n",
      "1243\n",
      "1244\n",
      "1245\n",
      "1246\n",
      "1247\n",
      "1248\n",
      "1249\n",
      "1250\n",
      "1251\n",
      "1252\n",
      "1253\n",
      "1254\n",
      "1255\n",
      "1256\n",
      "1257\n",
      "1258\n",
      "1259\n",
      "1260\n",
      "1261\n",
      "1262\n",
      "1263\n",
      "1264\n",
      "1265\n",
      "1266\n",
      "1267\n",
      "1268\n",
      "1269\n",
      "1270\n",
      "1271\n",
      "1272\n",
      "1273\n",
      "1274\n",
      "1275\n",
      "1276\n",
      "1277\n",
      "1278\n",
      "1279\n",
      "1280\n",
      "1281\n",
      "1282\n",
      "1283\n",
      "1284\n",
      "1285\n",
      "1286\n",
      "1287\n",
      "1288\n",
      "1289\n",
      "1290\n",
      "1291\n",
      "1292\n",
      "1293\n",
      "1294\n",
      "1295\n",
      "1296\n",
      "1297\n",
      "1298\n",
      "1299\n",
      "1300\n",
      "1301\n",
      "1302\n",
      "1303\n",
      "1304\n",
      "1305\n",
      "1306\n",
      "1307\n",
      "1308\n",
      "1309\n",
      "1310\n",
      "1311\n",
      "1312\n",
      "1313\n",
      "1314\n",
      "1315\n",
      "1316\n",
      "1317\n",
      "1318\n",
      "1319\n",
      "1320\n",
      "1321\n",
      "1322\n",
      "1323\n",
      "1324\n",
      "1325\n",
      "1326\n",
      "1327\n",
      "1328\n",
      "1329\n",
      "1330\n",
      "1331\n",
      "1332\n",
      "1333\n",
      "1334\n",
      "1335\n",
      "1336\n",
      "1337\n",
      "1338\n",
      "1339\n",
      "1340\n",
      "1341\n",
      "1342\n",
      "1343\n",
      "1344\n",
      "1345\n",
      "1346\n",
      "1347\n",
      "1348\n",
      "1349\n",
      "1350\n",
      "1351\n",
      "1352\n",
      "1353\n",
      "1354\n",
      "1355\n",
      "1356\n",
      "1357\n",
      "1358\n",
      "1359\n",
      "1360\n",
      "1361\n",
      "1362\n",
      "1363\n",
      "1364\n",
      "1365\n",
      "1366\n",
      "1367\n",
      "1368\n",
      "1369\n",
      "1370\n",
      "1371\n",
      "1372\n",
      "1373\n",
      "1374\n",
      "1375\n",
      "1376\n",
      "1377\n",
      "1378\n",
      "1379\n",
      "1380\n",
      "1381\n",
      "1382\n",
      "1383\n",
      "1384\n",
      "1385\n",
      "1386\n",
      "1387\n",
      "1388\n",
      "1389\n",
      "1390\n",
      "1391\n",
      "1392\n",
      "1393\n",
      "1394\n",
      "1395\n",
      "1396\n",
      "1397\n",
      "1398\n",
      "1399\n",
      "1400\n",
      "1401\n",
      "1402\n",
      "1403\n",
      "1404\n",
      "1405\n",
      "1406\n",
      "1407\n",
      "1408\n",
      "1409\n",
      "1410\n",
      "1411\n",
      "1412\n",
      "1413\n",
      "1414\n",
      "1415\n",
      "1416\n",
      "1417\n",
      "1418\n",
      "1419\n",
      "1420\n",
      "1421\n",
      "1422\n",
      "1423\n",
      "1424\n",
      "1425\n",
      "1426\n",
      "1427\n",
      "1428\n",
      "1429\n",
      "1430\n",
      "1431\n",
      "1432\n",
      "1433\n",
      "1434\n",
      "1435\n",
      "1436\n",
      "1437\n",
      "1438\n",
      "1439\n",
      "1440\n",
      "1441\n",
      "1442\n",
      "1443\n",
      "1444\n",
      "1445\n",
      "1446\n",
      "1447\n",
      "1448\n",
      "1449\n",
      "1450\n",
      "1451\n",
      "1452\n",
      "1453\n",
      "1454\n",
      "1455\n",
      "1456\n",
      "1457\n",
      "1458\n",
      "1459\n",
      "1460\n",
      "1461\n",
      "1462\n",
      "1463\n",
      "1464\n",
      "1465\n",
      "1466\n",
      "1467\n",
      "1468\n",
      "1469\n",
      "1470\n",
      "1471\n",
      "1472\n",
      "1473\n",
      "1474\n",
      "1475\n",
      "1476\n",
      "1477\n",
      "1478\n",
      "1479\n",
      "1480\n",
      "1481\n",
      "1482\n",
      "1483\n",
      "1484\n",
      "1485\n",
      "1486\n",
      "1487\n",
      "1488\n",
      "1489\n",
      "1490\n",
      "1491\n",
      "1492\n",
      "1493\n",
      "1494\n",
      "1495\n",
      "1496\n",
      "1497\n",
      "1498\n",
      "1499\n",
      "1500\n",
      "1501\n",
      "1502\n",
      "1503\n",
      "1504\n",
      "1505\n",
      "1506\n",
      "1507\n",
      "1508\n",
      "1509\n",
      "1510\n",
      "1511\n",
      "1512\n",
      "1513\n",
      "1514\n",
      "1515\n",
      "1516\n",
      "1517\n",
      "1518\n",
      "1519\n",
      "1520\n",
      "1521\n",
      "1522\n",
      "1523\n",
      "1524\n",
      "1525\n",
      "1526\n",
      "1527\n",
      "1528\n",
      "1529\n",
      "1530\n",
      "1531\n",
      "1532\n",
      "1533\n",
      "1534\n",
      "1535\n",
      "1536\n",
      "1537\n",
      "1538\n",
      "1539\n",
      "1540\n",
      "1541\n",
      "1542\n",
      "1543\n",
      "1544\n",
      "1545\n",
      "1546\n",
      "1547\n",
      "1548\n",
      "1549\n",
      "1550\n",
      "1551\n",
      "1552\n",
      "1553\n",
      "1554\n",
      "1555\n",
      "1556\n",
      "1557\n",
      "1558\n",
      "1559\n",
      "1560\n",
      "1561\n",
      "1562\n",
      "1563\n",
      "1564\n",
      "1565\n",
      "1566\n",
      "1567\n",
      "1568\n",
      "1569\n",
      "1570\n",
      "1571\n",
      "1572\n",
      "1573\n",
      "1574\n",
      "1575\n",
      "1576\n",
      "1577\n",
      "1578\n",
      "1579\n",
      "1580\n",
      "1581\n",
      "1582\n",
      "1583\n",
      "1584\n",
      "1585\n",
      "1586\n",
      "1587\n",
      "1588\n",
      "1589\n",
      "1590\n",
      "1591\n",
      "1592\n",
      "1593\n",
      "1594\n",
      "1595\n",
      "1596\n",
      "1597\n",
      "1598\n",
      "1599\n",
      "1600\n",
      "1601\n",
      "1602\n",
      "1603\n",
      "1604\n",
      "1605\n",
      "1606\n",
      "1607\n",
      "1608\n",
      "1609\n",
      "1610\n",
      "1611\n",
      "1612\n",
      "1613\n",
      "1614\n",
      "1615\n",
      "1616\n",
      "1617\n",
      "1618\n",
      "1619\n",
      "1620\n",
      "1621\n",
      "1622\n",
      "1623\n",
      "1624\n",
      "1625\n",
      "1626\n",
      "1627\n",
      "1628\n",
      "1629\n",
      "1630\n",
      "1631\n",
      "1632\n",
      "1633\n",
      "1634\n",
      "1635\n",
      "1636\n",
      "1637\n",
      "1638\n",
      "1639\n",
      "1640\n",
      "1641\n",
      "1642\n",
      "1643\n"
     ]
    }
   ],
   "source": [
    "# Load audio files and extract MFCC features\n",
    "X_mfcc_1643 = []\n",
    "y_mfcc_1643 = []\n",
    "i=1\n",
    "level_path_2315 = [\"C:\\\\Users\\\\SSN\\\\E-DAIC1\\\\E-DAIC-SPLITTED\\\\Nonstress\\\\No\", \n",
    "              \"C:\\\\Users\\\\SSN\\\\E-DAIC1\\\\E-DAIC-SPLITTED\\\\Nonstress\\\\Mild\",\n",
    "              \"C:\\\\Users\\\\SSN\\\\E-DAIC1\\\\E-DAIC-SPLITTED\\\\Stress\\\\Moderate\",\n",
    "              \"C:\\\\Users\\\\SSN\\\\E-DAIC1\\\\E-DAIC-SPLITTED\\\\Stress\\\\Severe\",\n",
    "              \"C:\\\\Users\\\\SSN\\\\E-DAIC1\\\\E-DAIC-SPLITTED\\\\Stress\\\\Extreme\"]\n",
    "\n",
    "for level in level_path_2315:\n",
    "    for file in os.listdir(level):\n",
    "        if file.startswith(\"Nonstress\") or file.startswith(\"Stress\"):\n",
    "            file_path = os.path.join(level, file)\n",
    "            # print(file_path)\n",
    "            mfcc = extract_mfcc_features(file_path)\n",
    "            X_mfcc_1643.append(mfcc)\n",
    "            y_mfcc_1643.append(level.split(\"\\\\\")[-2])\n",
    "\n",
    "            print(i)\n",
    "            i+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c8816d6-690b-42af-94ad-07a837bd9564",
   "metadata": {},
   "source": [
    "### Extracting MFCC features from the Splitted Augmented data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "073e9668-fe03-47b3-bbe2-044c19379fdb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "107\n",
      "108\n",
      "109\n",
      "110\n",
      "111\n",
      "112\n",
      "113\n",
      "114\n",
      "115\n",
      "116\n",
      "117\n",
      "118\n",
      "119\n",
      "120\n",
      "121\n",
      "122\n",
      "123\n",
      "124\n",
      "125\n",
      "126\n",
      "127\n",
      "128\n",
      "129\n",
      "130\n",
      "131\n",
      "132\n",
      "133\n",
      "134\n",
      "135\n",
      "136\n",
      "137\n",
      "138\n",
      "139\n",
      "140\n",
      "141\n",
      "142\n",
      "143\n",
      "144\n",
      "145\n",
      "146\n",
      "147\n",
      "148\n",
      "149\n",
      "150\n",
      "151\n",
      "152\n",
      "153\n",
      "154\n",
      "155\n",
      "156\n",
      "157\n",
      "158\n",
      "159\n",
      "160\n",
      "161\n",
      "162\n",
      "163\n",
      "164\n",
      "165\n",
      "166\n",
      "167\n",
      "168\n",
      "169\n",
      "170\n",
      "171\n",
      "172\n",
      "173\n",
      "174\n",
      "175\n",
      "176\n",
      "177\n",
      "178\n",
      "179\n",
      "180\n",
      "181\n",
      "182\n",
      "183\n",
      "184\n",
      "185\n",
      "186\n",
      "187\n",
      "188\n",
      "189\n",
      "190\n",
      "191\n",
      "192\n",
      "193\n",
      "194\n",
      "195\n",
      "196\n",
      "197\n",
      "198\n",
      "199\n",
      "200\n",
      "201\n",
      "202\n",
      "203\n",
      "204\n",
      "205\n",
      "206\n",
      "207\n",
      "208\n",
      "209\n",
      "210\n",
      "211\n",
      "212\n",
      "213\n",
      "214\n",
      "215\n",
      "216\n",
      "217\n",
      "218\n",
      "219\n",
      "220\n",
      "221\n",
      "222\n",
      "223\n",
      "224\n",
      "225\n",
      "226\n",
      "227\n",
      "228\n",
      "229\n",
      "230\n",
      "231\n",
      "232\n",
      "233\n",
      "234\n",
      "235\n",
      "236\n",
      "237\n",
      "238\n",
      "239\n",
      "240\n",
      "241\n",
      "242\n",
      "243\n",
      "244\n",
      "245\n",
      "246\n",
      "247\n",
      "248\n",
      "249\n",
      "250\n",
      "251\n",
      "252\n",
      "253\n",
      "254\n",
      "255\n",
      "256\n",
      "257\n",
      "258\n",
      "259\n",
      "260\n",
      "261\n",
      "262\n",
      "263\n",
      "264\n",
      "265\n",
      "266\n",
      "267\n",
      "268\n",
      "269\n",
      "270\n",
      "271\n",
      "272\n",
      "273\n",
      "274\n",
      "275\n",
      "276\n",
      "277\n",
      "278\n",
      "279\n",
      "280\n",
      "281\n",
      "282\n",
      "283\n",
      "284\n",
      "285\n",
      "286\n",
      "287\n",
      "288\n",
      "289\n",
      "290\n",
      "291\n",
      "292\n",
      "293\n",
      "294\n",
      "295\n",
      "296\n",
      "297\n",
      "298\n",
      "299\n",
      "300\n",
      "301\n",
      "302\n",
      "303\n",
      "304\n",
      "305\n",
      "306\n",
      "307\n",
      "308\n",
      "309\n",
      "310\n",
      "311\n",
      "312\n",
      "313\n",
      "314\n",
      "315\n",
      "316\n",
      "317\n",
      "318\n",
      "319\n",
      "320\n",
      "321\n",
      "322\n",
      "323\n",
      "324\n",
      "325\n",
      "326\n",
      "327\n",
      "328\n",
      "329\n",
      "330\n",
      "331\n",
      "332\n",
      "333\n",
      "334\n",
      "335\n",
      "336\n",
      "337\n",
      "338\n",
      "339\n",
      "340\n",
      "341\n",
      "342\n",
      "343\n",
      "344\n",
      "345\n",
      "346\n",
      "347\n",
      "348\n",
      "349\n",
      "350\n",
      "351\n",
      "352\n",
      "353\n",
      "354\n",
      "355\n",
      "356\n",
      "357\n",
      "358\n",
      "359\n",
      "360\n",
      "361\n",
      "362\n",
      "363\n",
      "364\n",
      "365\n",
      "366\n",
      "367\n",
      "368\n",
      "369\n",
      "370\n",
      "371\n",
      "372\n",
      "373\n",
      "374\n",
      "375\n",
      "376\n",
      "377\n",
      "378\n",
      "379\n",
      "380\n",
      "381\n",
      "382\n",
      "383\n",
      "384\n",
      "385\n",
      "386\n",
      "387\n",
      "388\n",
      "389\n",
      "390\n",
      "391\n",
      "392\n",
      "393\n",
      "394\n",
      "395\n",
      "396\n",
      "397\n",
      "398\n",
      "399\n",
      "400\n",
      "401\n",
      "402\n",
      "403\n",
      "404\n",
      "405\n",
      "406\n",
      "407\n",
      "408\n",
      "409\n",
      "410\n",
      "411\n",
      "412\n",
      "413\n",
      "414\n",
      "415\n",
      "416\n",
      "417\n",
      "418\n",
      "419\n",
      "420\n",
      "421\n",
      "422\n",
      "423\n",
      "424\n",
      "425\n",
      "426\n",
      "427\n",
      "428\n",
      "429\n",
      "430\n",
      "431\n",
      "432\n",
      "433\n",
      "434\n",
      "435\n",
      "436\n",
      "437\n",
      "438\n",
      "439\n",
      "440\n",
      "441\n",
      "442\n",
      "443\n",
      "444\n",
      "445\n",
      "446\n",
      "447\n",
      "448\n",
      "449\n",
      "450\n",
      "451\n",
      "452\n",
      "453\n",
      "454\n",
      "455\n",
      "456\n",
      "457\n",
      "458\n",
      "459\n",
      "460\n",
      "461\n",
      "462\n",
      "463\n",
      "464\n",
      "465\n",
      "466\n",
      "467\n",
      "468\n",
      "469\n",
      "470\n",
      "471\n",
      "472\n",
      "473\n",
      "474\n",
      "475\n",
      "476\n",
      "477\n",
      "478\n",
      "479\n",
      "480\n",
      "481\n",
      "482\n",
      "483\n",
      "484\n",
      "485\n",
      "486\n",
      "487\n",
      "488\n",
      "489\n",
      "490\n",
      "491\n",
      "492\n",
      "493\n",
      "494\n",
      "495\n",
      "496\n",
      "497\n",
      "498\n",
      "499\n",
      "500\n",
      "501\n",
      "502\n",
      "503\n",
      "504\n",
      "505\n",
      "506\n",
      "507\n",
      "508\n",
      "509\n",
      "510\n",
      "511\n",
      "512\n",
      "513\n",
      "514\n",
      "515\n",
      "516\n",
      "517\n",
      "518\n",
      "519\n",
      "520\n",
      "521\n",
      "522\n",
      "523\n",
      "524\n",
      "525\n",
      "526\n",
      "527\n",
      "528\n",
      "529\n",
      "530\n",
      "531\n",
      "532\n",
      "533\n",
      "534\n",
      "535\n",
      "536\n",
      "537\n",
      "538\n",
      "539\n",
      "540\n",
      "541\n",
      "542\n",
      "543\n",
      "544\n",
      "545\n",
      "546\n",
      "547\n",
      "548\n",
      "549\n",
      "550\n",
      "551\n",
      "552\n",
      "553\n",
      "554\n",
      "555\n",
      "556\n",
      "557\n",
      "558\n",
      "559\n",
      "560\n",
      "561\n",
      "562\n",
      "563\n",
      "564\n",
      "565\n",
      "566\n",
      "567\n",
      "568\n",
      "569\n",
      "570\n",
      "571\n",
      "572\n",
      "573\n",
      "574\n",
      "575\n",
      "576\n",
      "577\n",
      "578\n",
      "579\n",
      "580\n",
      "581\n",
      "582\n",
      "583\n",
      "584\n",
      "585\n",
      "586\n",
      "587\n",
      "588\n",
      "589\n",
      "590\n",
      "591\n",
      "592\n",
      "593\n",
      "594\n",
      "595\n",
      "596\n",
      "597\n",
      "598\n",
      "599\n",
      "600\n",
      "601\n",
      "602\n",
      "603\n",
      "604\n",
      "605\n",
      "606\n",
      "607\n",
      "608\n",
      "609\n",
      "610\n",
      "611\n",
      "612\n",
      "613\n",
      "614\n",
      "615\n",
      "616\n",
      "617\n",
      "618\n",
      "619\n",
      "620\n",
      "621\n",
      "622\n",
      "623\n",
      "624\n",
      "625\n",
      "626\n",
      "627\n",
      "628\n",
      "629\n",
      "630\n",
      "631\n",
      "632\n",
      "633\n",
      "634\n",
      "635\n",
      "636\n",
      "637\n",
      "638\n",
      "639\n",
      "640\n",
      "641\n",
      "642\n",
      "643\n",
      "644\n",
      "645\n",
      "646\n",
      "647\n",
      "648\n",
      "649\n",
      "650\n",
      "651\n",
      "652\n",
      "653\n",
      "654\n",
      "655\n",
      "656\n",
      "657\n",
      "658\n",
      "659\n",
      "660\n",
      "661\n",
      "662\n",
      "663\n",
      "664\n",
      "665\n",
      "666\n",
      "667\n",
      "668\n",
      "669\n",
      "670\n",
      "671\n",
      "672\n",
      "673\n",
      "674\n",
      "675\n",
      "676\n",
      "677\n",
      "678\n",
      "679\n",
      "680\n",
      "681\n",
      "682\n",
      "683\n",
      "684\n",
      "685\n",
      "686\n",
      "687\n",
      "688\n",
      "689\n",
      "690\n",
      "691\n",
      "692\n",
      "693\n",
      "694\n",
      "695\n",
      "696\n",
      "697\n",
      "698\n",
      "699\n",
      "700\n",
      "701\n",
      "702\n",
      "703\n",
      "704\n",
      "705\n",
      "706\n",
      "707\n",
      "708\n",
      "709\n",
      "710\n",
      "711\n",
      "712\n",
      "713\n",
      "714\n",
      "715\n",
      "716\n",
      "717\n",
      "718\n",
      "719\n",
      "720\n",
      "721\n",
      "722\n",
      "723\n",
      "724\n",
      "725\n",
      "726\n",
      "727\n",
      "728\n",
      "729\n",
      "730\n",
      "731\n",
      "732\n",
      "733\n",
      "734\n",
      "735\n",
      "736\n",
      "737\n",
      "738\n",
      "739\n",
      "740\n",
      "741\n",
      "742\n",
      "743\n",
      "744\n",
      "745\n",
      "746\n",
      "747\n",
      "748\n",
      "749\n",
      "750\n",
      "751\n",
      "752\n",
      "753\n",
      "754\n",
      "755\n",
      "756\n",
      "757\n",
      "758\n",
      "759\n",
      "760\n",
      "761\n",
      "762\n",
      "763\n",
      "764\n",
      "765\n",
      "766\n",
      "767\n",
      "768\n",
      "769\n",
      "770\n",
      "771\n",
      "772\n",
      "773\n",
      "774\n",
      "775\n",
      "776\n",
      "777\n",
      "778\n",
      "779\n",
      "780\n",
      "781\n",
      "782\n",
      "783\n",
      "784\n",
      "785\n",
      "786\n",
      "787\n",
      "788\n",
      "789\n",
      "790\n",
      "791\n",
      "792\n",
      "793\n",
      "794\n",
      "795\n",
      "796\n",
      "797\n",
      "798\n",
      "799\n",
      "800\n",
      "801\n",
      "802\n",
      "803\n",
      "804\n",
      "805\n",
      "806\n",
      "807\n",
      "808\n",
      "809\n",
      "810\n",
      "811\n",
      "812\n",
      "813\n",
      "814\n",
      "815\n",
      "816\n",
      "817\n",
      "818\n",
      "819\n",
      "820\n",
      "821\n",
      "822\n",
      "823\n",
      "824\n",
      "825\n",
      "826\n",
      "827\n",
      "828\n",
      "829\n",
      "830\n",
      "831\n",
      "832\n",
      "833\n",
      "834\n",
      "835\n",
      "836\n",
      "837\n",
      "838\n",
      "839\n",
      "840\n",
      "841\n",
      "842\n",
      "843\n",
      "844\n",
      "845\n",
      "846\n",
      "847\n",
      "848\n",
      "849\n",
      "850\n",
      "851\n",
      "852\n",
      "853\n",
      "854\n",
      "855\n",
      "856\n",
      "857\n",
      "858\n",
      "859\n",
      "860\n",
      "861\n",
      "862\n",
      "863\n",
      "864\n",
      "865\n",
      "866\n",
      "867\n",
      "868\n",
      "869\n",
      "870\n",
      "871\n",
      "872\n",
      "873\n",
      "874\n",
      "875\n",
      "876\n",
      "877\n",
      "878\n",
      "879\n",
      "880\n",
      "881\n",
      "882\n",
      "883\n",
      "884\n",
      "885\n",
      "886\n",
      "887\n",
      "888\n",
      "889\n",
      "890\n",
      "891\n",
      "892\n",
      "893\n",
      "894\n",
      "895\n",
      "896\n",
      "897\n",
      "898\n",
      "899\n",
      "900\n",
      "901\n",
      "902\n",
      "903\n",
      "904\n",
      "905\n",
      "906\n",
      "907\n",
      "908\n",
      "909\n",
      "910\n",
      "911\n",
      "912\n",
      "913\n",
      "914\n",
      "915\n",
      "916\n",
      "917\n",
      "918\n",
      "919\n",
      "920\n",
      "921\n",
      "922\n",
      "923\n",
      "924\n",
      "925\n",
      "926\n",
      "927\n",
      "928\n",
      "929\n",
      "930\n",
      "931\n",
      "932\n",
      "933\n",
      "934\n",
      "935\n",
      "936\n",
      "937\n",
      "938\n",
      "939\n",
      "940\n",
      "941\n",
      "942\n",
      "943\n",
      "944\n",
      "945\n",
      "946\n",
      "947\n",
      "948\n",
      "949\n",
      "950\n",
      "951\n",
      "952\n",
      "953\n",
      "954\n",
      "955\n",
      "956\n",
      "957\n",
      "958\n",
      "959\n",
      "960\n",
      "961\n",
      "962\n",
      "963\n",
      "964\n",
      "965\n",
      "966\n",
      "967\n",
      "968\n",
      "969\n",
      "970\n",
      "971\n",
      "972\n",
      "973\n",
      "974\n",
      "975\n",
      "976\n",
      "977\n",
      "978\n",
      "979\n",
      "980\n",
      "981\n",
      "982\n",
      "983\n",
      "984\n",
      "985\n",
      "986\n",
      "987\n",
      "988\n",
      "989\n",
      "990\n",
      "991\n",
      "992\n",
      "993\n",
      "994\n",
      "995\n",
      "996\n",
      "997\n",
      "998\n",
      "999\n",
      "1000\n",
      "1001\n",
      "1002\n",
      "1003\n",
      "1004\n",
      "1005\n",
      "1006\n",
      "1007\n",
      "1008\n",
      "1009\n",
      "1010\n",
      "1011\n",
      "1012\n",
      "1013\n",
      "1014\n",
      "1015\n",
      "1016\n",
      "1017\n",
      "1018\n",
      "1019\n",
      "1020\n",
      "1021\n",
      "1022\n",
      "1023\n",
      "1024\n",
      "1025\n",
      "1026\n",
      "1027\n",
      "1028\n",
      "1029\n",
      "1030\n",
      "1031\n",
      "1032\n",
      "1033\n",
      "1034\n",
      "1035\n",
      "1036\n",
      "1037\n",
      "1038\n",
      "1039\n",
      "1040\n",
      "1041\n",
      "1042\n",
      "1043\n",
      "1044\n",
      "1045\n",
      "1046\n",
      "1047\n",
      "1048\n",
      "1049\n",
      "1050\n",
      "1051\n",
      "1052\n",
      "1053\n",
      "1054\n",
      "1055\n",
      "1056\n",
      "1057\n",
      "1058\n",
      "1059\n",
      "1060\n",
      "1061\n",
      "1062\n",
      "1063\n",
      "1064\n",
      "1065\n",
      "1066\n",
      "1067\n",
      "1068\n",
      "1069\n",
      "1070\n",
      "1071\n",
      "1072\n",
      "1073\n",
      "1074\n",
      "1075\n",
      "1076\n",
      "1077\n",
      "1078\n",
      "1079\n",
      "1080\n",
      "1081\n",
      "1082\n",
      "1083\n",
      "1084\n",
      "1085\n",
      "1086\n",
      "1087\n",
      "1088\n",
      "1089\n",
      "1090\n",
      "1091\n",
      "1092\n",
      "1093\n",
      "1094\n",
      "1095\n",
      "1096\n",
      "1097\n",
      "1098\n",
      "1099\n",
      "1100\n",
      "1101\n",
      "1102\n",
      "1103\n",
      "1104\n",
      "1105\n",
      "1106\n",
      "1107\n",
      "1108\n",
      "1109\n",
      "1110\n",
      "1111\n",
      "1112\n",
      "1113\n",
      "1114\n",
      "1115\n",
      "1116\n",
      "1117\n",
      "1118\n",
      "1119\n",
      "1120\n",
      "1121\n",
      "1122\n",
      "1123\n",
      "1124\n",
      "1125\n",
      "1126\n",
      "1127\n",
      "1128\n",
      "1129\n",
      "1130\n",
      "1131\n",
      "1132\n",
      "1133\n",
      "1134\n",
      "1135\n",
      "1136\n",
      "1137\n",
      "1138\n",
      "1139\n",
      "1140\n",
      "1141\n",
      "1142\n",
      "1143\n",
      "1144\n",
      "1145\n",
      "1146\n",
      "1147\n",
      "1148\n",
      "1149\n",
      "1150\n",
      "1151\n",
      "1152\n",
      "1153\n",
      "1154\n",
      "1155\n",
      "1156\n",
      "1157\n",
      "1158\n",
      "1159\n",
      "1160\n",
      "1161\n",
      "1162\n",
      "1163\n",
      "1164\n",
      "1165\n",
      "1166\n",
      "1167\n",
      "1168\n",
      "1169\n",
      "1170\n",
      "1171\n",
      "1172\n",
      "1173\n",
      "1174\n",
      "1175\n",
      "1176\n",
      "1177\n",
      "1178\n",
      "1179\n",
      "1180\n",
      "1181\n",
      "1182\n",
      "1183\n",
      "1184\n",
      "1185\n",
      "1186\n",
      "1187\n",
      "1188\n",
      "1189\n",
      "1190\n",
      "1191\n",
      "1192\n",
      "1193\n",
      "1194\n",
      "1195\n",
      "1196\n",
      "1197\n",
      "1198\n",
      "1199\n",
      "1200\n",
      "1201\n",
      "1202\n",
      "1203\n",
      "1204\n",
      "1205\n",
      "1206\n",
      "1207\n",
      "1208\n",
      "1209\n",
      "1210\n",
      "1211\n",
      "1212\n",
      "1213\n",
      "1214\n",
      "1215\n",
      "1216\n",
      "1217\n",
      "1218\n",
      "1219\n",
      "1220\n",
      "1221\n",
      "1222\n",
      "1223\n",
      "1224\n",
      "1225\n",
      "1226\n",
      "1227\n",
      "1228\n",
      "1229\n",
      "1230\n",
      "1231\n",
      "1232\n",
      "1233\n",
      "1234\n",
      "1235\n",
      "1236\n",
      "1237\n",
      "1238\n",
      "1239\n",
      "1240\n",
      "1241\n",
      "1242\n",
      "1243\n",
      "1244\n",
      "1245\n",
      "1246\n",
      "1247\n",
      "1248\n",
      "1249\n",
      "1250\n",
      "1251\n",
      "1252\n",
      "1253\n",
      "1254\n",
      "1255\n",
      "1256\n",
      "1257\n",
      "1258\n",
      "1259\n",
      "1260\n",
      "1261\n",
      "1262\n",
      "1263\n",
      "1264\n",
      "1265\n",
      "1266\n",
      "1267\n",
      "1268\n",
      "1269\n",
      "1270\n",
      "1271\n",
      "1272\n",
      "1273\n",
      "1274\n",
      "1275\n",
      "1276\n",
      "1277\n",
      "1278\n",
      "1279\n",
      "1280\n",
      "1281\n",
      "1282\n",
      "1283\n",
      "1284\n",
      "1285\n",
      "1286\n",
      "1287\n",
      "1288\n",
      "1289\n",
      "1290\n",
      "1291\n",
      "1292\n",
      "1293\n",
      "1294\n",
      "1295\n",
      "1296\n",
      "1297\n",
      "1298\n",
      "1299\n",
      "1300\n",
      "1301\n",
      "1302\n",
      "1303\n",
      "1304\n",
      "1305\n",
      "1306\n",
      "1307\n",
      "1308\n",
      "1309\n",
      "1310\n",
      "1311\n",
      "1312\n",
      "1313\n",
      "1314\n",
      "1315\n",
      "1316\n",
      "1317\n",
      "1318\n",
      "1319\n",
      "1320\n",
      "1321\n",
      "1322\n",
      "1323\n",
      "1324\n",
      "1325\n",
      "1326\n",
      "1327\n",
      "1328\n",
      "1329\n",
      "1330\n",
      "1331\n",
      "1332\n",
      "1333\n",
      "1334\n",
      "1335\n",
      "1336\n",
      "1337\n",
      "1338\n",
      "1339\n",
      "1340\n",
      "1341\n",
      "1342\n",
      "1343\n",
      "1344\n",
      "1345\n",
      "1346\n",
      "1347\n",
      "1348\n",
      "1349\n",
      "1350\n",
      "1351\n",
      "1352\n",
      "1353\n",
      "1354\n",
      "1355\n",
      "1356\n",
      "1357\n",
      "1358\n",
      "1359\n",
      "1360\n",
      "1361\n",
      "1362\n",
      "1363\n",
      "1364\n",
      "1365\n",
      "1366\n",
      "1367\n",
      "1368\n",
      "1369\n",
      "1370\n",
      "1371\n",
      "1372\n",
      "1373\n",
      "1374\n",
      "1375\n",
      "1376\n",
      "1377\n",
      "1378\n",
      "1379\n",
      "1380\n",
      "1381\n",
      "1382\n",
      "1383\n",
      "1384\n",
      "1385\n",
      "1386\n",
      "1387\n",
      "1388\n",
      "1389\n",
      "1390\n",
      "1391\n",
      "1392\n",
      "1393\n",
      "1394\n",
      "1395\n",
      "1396\n",
      "1397\n",
      "1398\n",
      "1399\n",
      "1400\n",
      "1401\n",
      "1402\n",
      "1403\n",
      "1404\n",
      "1405\n",
      "1406\n",
      "1407\n",
      "1408\n",
      "1409\n",
      "1410\n",
      "1411\n",
      "1412\n",
      "1413\n",
      "1414\n",
      "1415\n",
      "1416\n",
      "1417\n",
      "1418\n",
      "1419\n",
      "1420\n",
      "1421\n",
      "1422\n",
      "1423\n",
      "1424\n",
      "1425\n",
      "1426\n",
      "1427\n",
      "1428\n",
      "1429\n",
      "1430\n",
      "1431\n",
      "1432\n",
      "1433\n",
      "1434\n",
      "1435\n",
      "1436\n",
      "1437\n",
      "1438\n",
      "1439\n",
      "1440\n",
      "1441\n",
      "1442\n",
      "1443\n",
      "1444\n",
      "1445\n",
      "1446\n",
      "1447\n",
      "1448\n",
      "1449\n",
      "1450\n",
      "1451\n",
      "1452\n",
      "1453\n",
      "1454\n",
      "1455\n",
      "1456\n",
      "1457\n",
      "1458\n",
      "1459\n",
      "1460\n",
      "1461\n",
      "1462\n",
      "1463\n",
      "1464\n",
      "1465\n",
      "1466\n",
      "1467\n",
      "1468\n",
      "1469\n",
      "1470\n",
      "1471\n",
      "1472\n",
      "1473\n",
      "1474\n",
      "1475\n",
      "1476\n",
      "1477\n",
      "1478\n",
      "1479\n",
      "1480\n",
      "1481\n",
      "1482\n",
      "1483\n",
      "1484\n",
      "1485\n",
      "1486\n",
      "1487\n",
      "1488\n",
      "1489\n",
      "1490\n",
      "1491\n",
      "1492\n",
      "1493\n",
      "1494\n",
      "1495\n",
      "1496\n",
      "1497\n",
      "1498\n",
      "1499\n",
      "1500\n",
      "1501\n",
      "1502\n",
      "1503\n",
      "1504\n",
      "1505\n",
      "1506\n",
      "1507\n",
      "1508\n",
      "1509\n",
      "1510\n",
      "1511\n",
      "1512\n",
      "1513\n",
      "1514\n",
      "1515\n",
      "1516\n",
      "1517\n",
      "1518\n",
      "1519\n",
      "1520\n",
      "1521\n",
      "1522\n",
      "1523\n",
      "1524\n",
      "1525\n",
      "1526\n",
      "1527\n",
      "1528\n",
      "1529\n",
      "1530\n",
      "1531\n",
      "1532\n",
      "1533\n",
      "1534\n",
      "1535\n",
      "1536\n",
      "1537\n",
      "1538\n",
      "1539\n",
      "1540\n",
      "1541\n",
      "1542\n",
      "1543\n",
      "1544\n",
      "1545\n",
      "1546\n",
      "1547\n",
      "1548\n",
      "1549\n",
      "1550\n",
      "1551\n",
      "1552\n",
      "1553\n",
      "1554\n",
      "1555\n",
      "1556\n",
      "1557\n",
      "1558\n",
      "1559\n",
      "1560\n",
      "1561\n",
      "1562\n",
      "1563\n",
      "1564\n",
      "1565\n",
      "1566\n",
      "1567\n",
      "1568\n",
      "1569\n",
      "1570\n",
      "1571\n",
      "1572\n",
      "1573\n",
      "1574\n",
      "1575\n",
      "1576\n",
      "1577\n",
      "1578\n",
      "1579\n",
      "1580\n",
      "1581\n",
      "1582\n",
      "1583\n",
      "1584\n",
      "1585\n",
      "1586\n",
      "1587\n",
      "1588\n",
      "1589\n",
      "1590\n",
      "1591\n",
      "1592\n",
      "1593\n",
      "1594\n",
      "1595\n",
      "1596\n",
      "1597\n",
      "1598\n",
      "1599\n",
      "1600\n",
      "1601\n",
      "1602\n",
      "1603\n",
      "1604\n",
      "1605\n",
      "1606\n",
      "1607\n",
      "1608\n",
      "1609\n",
      "1610\n",
      "1611\n",
      "1612\n",
      "1613\n",
      "1614\n",
      "1615\n",
      "1616\n",
      "1617\n",
      "1618\n",
      "1619\n",
      "1620\n",
      "1621\n",
      "1622\n",
      "1623\n",
      "1624\n",
      "1625\n",
      "1626\n",
      "1627\n",
      "1628\n",
      "1629\n",
      "1630\n",
      "1631\n",
      "1632\n",
      "1633\n",
      "1634\n",
      "1635\n",
      "1636\n",
      "1637\n",
      "1638\n",
      "1639\n",
      "1640\n",
      "1641\n",
      "1642\n",
      "1643\n",
      "1644\n",
      "1645\n",
      "1646\n",
      "1647\n",
      "1648\n",
      "1649\n",
      "1650\n",
      "1651\n",
      "1652\n",
      "1653\n",
      "1654\n",
      "1655\n",
      "1656\n",
      "1657\n",
      "1658\n",
      "1659\n",
      "1660\n",
      "1661\n",
      "1662\n",
      "1663\n",
      "1664\n",
      "1665\n",
      "1666\n",
      "1667\n",
      "1668\n",
      "1669\n",
      "1670\n",
      "1671\n",
      "1672\n",
      "1673\n",
      "1674\n",
      "1675\n",
      "1676\n",
      "1677\n",
      "1678\n",
      "1679\n",
      "1680\n",
      "1681\n",
      "1682\n",
      "1683\n",
      "1684\n",
      "1685\n",
      "1686\n",
      "1687\n",
      "1688\n",
      "1689\n",
      "1690\n",
      "1691\n",
      "1692\n",
      "1693\n",
      "1694\n",
      "1695\n",
      "1696\n",
      "1697\n",
      "1698\n",
      "1699\n",
      "1700\n",
      "1701\n",
      "1702\n",
      "1703\n",
      "1704\n",
      "1705\n",
      "1706\n",
      "1707\n",
      "1708\n",
      "1709\n",
      "1710\n",
      "1711\n",
      "1712\n",
      "1713\n",
      "1714\n",
      "1715\n",
      "1716\n",
      "1717\n",
      "1718\n",
      "1719\n",
      "1720\n",
      "1721\n",
      "1722\n",
      "1723\n",
      "1724\n",
      "1725\n",
      "1726\n",
      "1727\n",
      "1728\n",
      "1729\n",
      "1730\n",
      "1731\n",
      "1732\n",
      "1733\n",
      "1734\n",
      "1735\n",
      "1736\n",
      "1737\n",
      "1738\n",
      "1739\n",
      "1740\n",
      "1741\n",
      "1742\n",
      "1743\n",
      "1744\n",
      "1745\n",
      "1746\n",
      "1747\n",
      "1748\n",
      "1749\n",
      "1750\n",
      "1751\n",
      "1752\n",
      "1753\n",
      "1754\n",
      "1755\n",
      "1756\n",
      "1757\n",
      "1758\n",
      "1759\n",
      "1760\n",
      "1761\n",
      "1762\n",
      "1763\n",
      "1764\n",
      "1765\n",
      "1766\n",
      "1767\n",
      "1768\n",
      "1769\n",
      "1770\n",
      "1771\n",
      "1772\n",
      "1773\n",
      "1774\n",
      "1775\n",
      "1776\n",
      "1777\n",
      "1778\n",
      "1779\n",
      "1780\n",
      "1781\n",
      "1782\n",
      "1783\n",
      "1784\n",
      "1785\n",
      "1786\n",
      "1787\n",
      "1788\n",
      "1789\n",
      "1790\n",
      "1791\n",
      "1792\n",
      "1793\n",
      "1794\n",
      "1795\n",
      "1796\n",
      "1797\n",
      "1798\n",
      "1799\n",
      "1800\n",
      "1801\n",
      "1802\n",
      "1803\n",
      "1804\n",
      "1805\n",
      "1806\n",
      "1807\n",
      "1808\n",
      "1809\n",
      "1810\n",
      "1811\n",
      "1812\n",
      "1813\n",
      "1814\n",
      "1815\n",
      "1816\n",
      "1817\n",
      "1818\n",
      "1819\n",
      "1820\n",
      "1821\n",
      "1822\n",
      "1823\n",
      "1824\n",
      "1825\n",
      "1826\n",
      "1827\n",
      "1828\n",
      "1829\n",
      "1830\n",
      "1831\n",
      "1832\n",
      "1833\n",
      "1834\n",
      "1835\n",
      "1836\n",
      "1837\n",
      "1838\n",
      "1839\n",
      "1840\n",
      "1841\n",
      "1842\n",
      "1843\n",
      "1844\n",
      "1845\n",
      "1846\n",
      "1847\n",
      "1848\n",
      "1849\n",
      "1850\n",
      "1851\n",
      "1852\n",
      "1853\n",
      "1854\n",
      "1855\n",
      "1856\n",
      "1857\n",
      "1858\n",
      "1859\n",
      "1860\n",
      "1861\n",
      "1862\n",
      "1863\n",
      "1864\n",
      "1865\n",
      "1866\n",
      "1867\n",
      "1868\n",
      "1869\n",
      "1870\n",
      "1871\n",
      "1872\n",
      "1873\n",
      "1874\n",
      "1875\n",
      "1876\n",
      "1877\n",
      "1878\n",
      "1879\n",
      "1880\n",
      "1881\n",
      "1882\n",
      "1883\n",
      "1884\n",
      "1885\n",
      "1886\n",
      "1887\n",
      "1888\n",
      "1889\n",
      "1890\n",
      "1891\n",
      "1892\n",
      "1893\n",
      "1894\n",
      "1895\n",
      "1896\n",
      "1897\n",
      "1898\n",
      "1899\n",
      "1900\n",
      "1901\n",
      "1902\n",
      "1903\n",
      "1904\n",
      "1905\n",
      "1906\n",
      "1907\n",
      "1908\n",
      "1909\n",
      "1910\n",
      "1911\n",
      "1912\n",
      "1913\n",
      "1914\n",
      "1915\n",
      "1916\n",
      "1917\n",
      "1918\n",
      "1919\n",
      "1920\n",
      "1921\n",
      "1922\n",
      "1923\n",
      "1924\n",
      "1925\n",
      "1926\n",
      "1927\n",
      "1928\n",
      "1929\n",
      "1930\n",
      "1931\n",
      "1932\n",
      "1933\n",
      "1934\n",
      "1935\n",
      "1936\n",
      "1937\n",
      "1938\n",
      "1939\n",
      "1940\n",
      "1941\n",
      "1942\n",
      "1943\n",
      "1944\n",
      "1945\n",
      "1946\n",
      "1947\n",
      "1948\n",
      "1949\n",
      "1950\n",
      "1951\n",
      "1952\n",
      "1953\n",
      "1954\n",
      "1955\n",
      "1956\n",
      "1957\n",
      "1958\n",
      "1959\n",
      "1960\n",
      "1961\n",
      "1962\n",
      "1963\n",
      "1964\n",
      "1965\n",
      "1966\n",
      "1967\n",
      "1968\n",
      "1969\n",
      "1970\n",
      "1971\n",
      "1972\n",
      "1973\n",
      "1974\n",
      "1975\n",
      "1976\n",
      "1977\n",
      "1978\n",
      "1979\n",
      "1980\n",
      "1981\n",
      "1982\n",
      "1983\n",
      "1984\n",
      "1985\n",
      "1986\n",
      "1987\n",
      "1988\n",
      "1989\n",
      "1990\n",
      "1991\n",
      "1992\n",
      "1993\n",
      "1994\n",
      "1995\n",
      "1996\n",
      "1997\n",
      "1998\n",
      "1999\n",
      "2000\n",
      "2001\n",
      "2002\n",
      "2003\n",
      "2004\n",
      "2005\n",
      "2006\n",
      "2007\n",
      "2008\n",
      "2009\n",
      "2010\n",
      "2011\n",
      "2012\n",
      "2013\n",
      "2014\n",
      "2015\n",
      "2016\n",
      "2017\n",
      "2018\n",
      "2019\n",
      "2020\n",
      "2021\n",
      "2022\n",
      "2023\n",
      "2024\n",
      "2025\n",
      "2026\n",
      "2027\n",
      "2028\n",
      "2029\n",
      "2030\n",
      "2031\n",
      "2032\n",
      "2033\n",
      "2034\n",
      "2035\n",
      "2036\n",
      "2037\n",
      "2038\n",
      "2039\n",
      "2040\n",
      "2041\n",
      "2042\n",
      "2043\n",
      "2044\n",
      "2045\n",
      "2046\n",
      "2047\n",
      "2048\n",
      "2049\n",
      "2050\n",
      "2051\n",
      "2052\n",
      "2053\n",
      "2054\n",
      "2055\n",
      "2056\n",
      "2057\n",
      "2058\n",
      "2059\n",
      "2060\n",
      "2061\n",
      "2062\n",
      "2063\n",
      "2064\n",
      "2065\n",
      "2066\n",
      "2067\n",
      "2068\n",
      "2069\n",
      "2070\n",
      "2071\n",
      "2072\n",
      "2073\n",
      "2074\n",
      "2075\n",
      "2076\n",
      "2077\n",
      "2078\n",
      "2079\n",
      "2080\n",
      "2081\n",
      "2082\n",
      "2083\n",
      "2084\n",
      "2085\n",
      "2086\n",
      "2087\n",
      "2088\n",
      "2089\n",
      "2090\n",
      "2091\n",
      "2092\n",
      "2093\n",
      "2094\n",
      "2095\n",
      "2096\n",
      "2097\n",
      "2098\n",
      "2099\n",
      "2100\n",
      "2101\n",
      "2102\n",
      "2103\n",
      "2104\n",
      "2105\n",
      "2106\n",
      "2107\n",
      "2108\n",
      "2109\n",
      "2110\n",
      "2111\n",
      "2112\n",
      "2113\n",
      "2114\n",
      "2115\n",
      "2116\n",
      "2117\n",
      "2118\n",
      "2119\n",
      "2120\n",
      "2121\n",
      "2122\n",
      "2123\n",
      "2124\n",
      "2125\n",
      "2126\n",
      "2127\n",
      "2128\n",
      "2129\n",
      "2130\n",
      "2131\n",
      "2132\n",
      "2133\n",
      "2134\n",
      "2135\n",
      "2136\n",
      "2137\n",
      "2138\n",
      "2139\n",
      "2140\n",
      "2141\n",
      "2142\n",
      "2143\n",
      "2144\n",
      "2145\n",
      "2146\n",
      "2147\n",
      "2148\n",
      "2149\n",
      "2150\n",
      "2151\n",
      "2152\n",
      "2153\n",
      "2154\n",
      "2155\n",
      "2156\n",
      "2157\n",
      "2158\n",
      "2159\n",
      "2160\n",
      "2161\n",
      "2162\n",
      "2163\n",
      "2164\n",
      "2165\n",
      "2166\n",
      "2167\n",
      "2168\n",
      "2169\n",
      "2170\n",
      "2171\n",
      "2172\n",
      "2173\n",
      "2174\n",
      "2175\n",
      "2176\n",
      "2177\n",
      "2178\n",
      "2179\n",
      "2180\n",
      "2181\n",
      "2182\n",
      "2183\n",
      "2184\n",
      "2185\n",
      "2186\n",
      "2187\n",
      "2188\n",
      "2189\n",
      "2190\n",
      "2191\n",
      "2192\n",
      "2193\n",
      "2194\n",
      "2195\n",
      "2196\n",
      "2197\n",
      "2198\n",
      "2199\n",
      "2200\n",
      "2201\n",
      "2202\n",
      "2203\n",
      "2204\n",
      "2205\n",
      "2206\n",
      "2207\n",
      "2208\n",
      "2209\n",
      "2210\n",
      "2211\n",
      "2212\n",
      "2213\n",
      "2214\n",
      "2215\n",
      "2216\n",
      "2217\n",
      "2218\n",
      "2219\n",
      "2220\n",
      "2221\n",
      "2222\n",
      "2223\n",
      "2224\n",
      "2225\n",
      "2226\n",
      "2227\n",
      "2228\n",
      "2229\n",
      "2230\n",
      "2231\n",
      "2232\n",
      "2233\n",
      "2234\n",
      "2235\n",
      "2236\n",
      "2237\n",
      "2238\n",
      "2239\n",
      "2240\n",
      "2241\n",
      "2242\n",
      "2243\n",
      "2244\n",
      "2245\n",
      "2246\n",
      "2247\n",
      "2248\n",
      "2249\n",
      "2250\n",
      "2251\n",
      "2252\n",
      "2253\n",
      "2254\n",
      "2255\n",
      "2256\n",
      "2257\n",
      "2258\n",
      "2259\n",
      "2260\n",
      "2261\n",
      "2262\n",
      "2263\n",
      "2264\n",
      "2265\n",
      "2266\n",
      "2267\n",
      "2268\n",
      "2269\n",
      "2270\n",
      "2271\n",
      "2272\n",
      "2273\n",
      "2274\n",
      "2275\n",
      "2276\n",
      "2277\n",
      "2278\n",
      "2279\n",
      "2280\n",
      "2281\n",
      "2282\n",
      "2283\n",
      "2284\n",
      "2285\n",
      "2286\n",
      "2287\n",
      "2288\n",
      "2289\n",
      "2290\n",
      "2291\n",
      "2292\n",
      "2293\n",
      "2294\n",
      "2295\n",
      "2296\n",
      "2297\n",
      "2298\n",
      "2299\n",
      "2300\n",
      "2301\n",
      "2302\n",
      "2303\n",
      "2304\n",
      "2305\n",
      "2306\n",
      "2307\n",
      "2308\n",
      "2309\n",
      "2310\n",
      "2311\n",
      "2312\n",
      "2313\n",
      "2314\n",
      "2315\n"
     ]
    }
   ],
   "source": [
    "# Load audio files and extract MFCC features\n",
    "X_A_mfcc_2315 = []\n",
    "y_A_mfcc_2315 = []\n",
    "i=1\n",
    "level_path_2315 = [\"C:\\\\Users\\\\SSN\\\\E-DAIC1\\\\E-DAIC-SPLITTED\\\\Nonstress\\\\No\", \n",
    "              \"C:\\\\Users\\\\SSN\\\\E-DAIC1\\\\E-DAIC-SPLITTED\\\\Nonstress\\\\Mild\",\n",
    "              \"C:\\\\Users\\\\SSN\\\\E-DAIC1\\\\E-DAIC-SPLITTED\\\\Stress\\\\Moderate\",\n",
    "              \"C:\\\\Users\\\\SSN\\\\E-DAIC1\\\\E-DAIC-SPLITTED\\\\Stress\\\\Severe\",\n",
    "              \"C:\\\\Users\\\\SSN\\\\E-DAIC1\\\\E-DAIC-SPLITTED\\\\Stress\\\\Extreme\"]\n",
    "\n",
    "for level in level_path_2315:\n",
    "    for file in os.listdir(level):\n",
    "        if file.startswith(\"A_Nonstress\") or file.startswith(\"A_Stress\"):\n",
    "            file_path = os.path.join(level, file)\n",
    "            # print(file_path)\n",
    "            mfcc = extract_mfcc_features(file_path)\n",
    "            X_A_mfcc_2315.append(mfcc)\n",
    "            y_A_mfcc_2315.append(level.split(\"\\\\\")[-2])\n",
    "\n",
    "            print(i)\n",
    "            i+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be499f79-1327-4806-864c-197341864505",
   "metadata": {},
   "source": [
    "# Actual Data(132)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "629cd9cb-04c8-4d57-81f1-a35bfeba1f4d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "y_mfcc_132_new = []\n",
    "for i in y_mfcc_132:\n",
    "    if i == \"Nonstress\":\n",
    "        y_mfcc_132_new.append(0)\n",
    "    elif i == \"Stress\":\n",
    "        y_mfcc_132_new.append(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e8c99fce-315f-4237-96f8-0490290899ed",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "y_mfcc_132 = y_mfcc_132_new\n",
    "print(y_mfcc_132)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "97fc421c-6a5d-4162-b94b-7ba605a0721b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_mfcc_132 = np.array(X_mfcc_132)\n",
    "y_mfcc_132 = np.array(y_mfcc_132)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9504aaf3-27bd-4c38-94e8-0e920810ed4e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-4.41858215e+02  8.90241394e+01  4.42410564e+00 ... -6.88594580e-01\n",
      "  -2.13312149e-01  3.24701697e-01]\n",
      " [-4.58407196e+02  1.21234566e+02 -2.52888113e-01 ... -2.05665082e-01\n",
      "   6.19398117e-01  2.15624347e-01]\n",
      " [-4.99765350e+02  9.64203949e+01  1.01493816e+01 ...  8.97891343e-01\n",
      "   5.99282026e-01  1.60692811e-01]\n",
      " ...\n",
      " [-6.62455750e+02  9.64516373e+01  1.48949585e+01 ... -1.30923942e-01\n",
      "   6.48874283e-01  1.79079831e+00]\n",
      " [-5.69818298e+02  9.76811523e+01  1.05054884e+01 ... -3.95787358e-01\n",
      "   3.95962954e-01 -2.61862457e-01]\n",
      " [-5.78540588e+02  5.12668076e+01  1.87248173e+01 ...  3.85449469e-01\n",
      "   6.80115879e-01  1.00725520e+00]] [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "print(X_mfcc_132, y_mfcc_132)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e4b8f98a-e412-433a-b423-c63e846782e7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "y_mfcc_132 = y_mfcc_132.reshape(1,132)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4dc1a035-dbb7-4472-b944-8618dae80e9a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(132, 1, 40)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.reshape(X_mfcc_132, (X_mfcc_132.shape[0], 1, X_mfcc_132.shape[1])).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4eb670ff-9fbc-4414-96f6-64d6ecaec79a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(132,)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.reshape(y_mfcc_132, (y_mfcc_132.shape[1],)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3971630a-7214-4d31-a876-5c61f61b17dc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(np.array(X_mfcc_132), y_mfcc_132[0], test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1184c05a-3b46-428c-bb86-1c62f0ee93a3",
   "metadata": {},
   "source": [
    "### Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b89cc339-cad9-49b0-9894-db7928ada863",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5925925925925926\n",
      "Accuracy: 0.5664835164835166\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.84      0.83        49\n",
      "           1       0.85      0.84      0.85        56\n",
      "\n",
      "    accuracy                           0.84       105\n",
      "   macro avg       0.84      0.84      0.84       105\n",
      "weighted avg       0.84      0.84      0.84       105\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.47      0.59        17\n",
      "           1       0.47      0.80      0.59        10\n",
      "\n",
      "    accuracy                           0.59        27\n",
      "   macro avg       0.64      0.64      0.59        27\n",
      "weighted avg       0.68      0.59      0.59        27\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# SVM\n",
    "SVM = SVC(kernel='linear', C=1, random_state=42)\n",
    "SVM.fit(X_train, y_train)\n",
    "print(\"Accuracy:\",accuracy_score(y_test, SVM.predict(X_test)))\n",
    "score = cross_val_score(SVM, X_mfcc_132, y_mfcc_132[0], cv=10)\n",
    "\n",
    "print(f\"Accuracy: {score.mean()}\")\n",
    "print(classification_report(y_train, SVM.predict(X_train)))\n",
    "print(classification_report(y_test, SVM.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b125e1a5-eb5a-413f-b5e5-f4cc499e028e",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "aeb8605a-fecc-45a7-bf26-175afb7354c8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.48148148148148145\n",
      "Accuracy: 0.5368131868131869\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        49\n",
      "           1       1.00      1.00      1.00        56\n",
      "\n",
      "    accuracy                           1.00       105\n",
      "   macro avg       1.00      1.00      1.00       105\n",
      "weighted avg       1.00      1.00      1.00       105\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.41      0.50        17\n",
      "           1       0.38      0.60      0.46        10\n",
      "\n",
      "    accuracy                           0.48        27\n",
      "   macro avg       0.51      0.51      0.48        27\n",
      "weighted avg       0.54      0.48      0.49        27\n",
      "\n"
     ]
    }
   ],
   "source": [
    "RandomForest = RandomForestClassifier(oob_score=True, random_state=42)\n",
    "RandomForest.fit(X_train,y_train)\n",
    "print(\"Accuracy:\",accuracy_score(y_test, RandomForest.predict(X_test)))\n",
    "\n",
    "score = cross_val_score(RandomForest, X_mfcc_132, y_mfcc_132[0], cv=10)\n",
    "print(f\"Accuracy: {score.mean()}\")\n",
    "print(classification_report(y_train, RandomForest.predict(X_train)))\n",
    "print(classification_report(y_test, RandomForest.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "786216ad-5165-4d35-a3ad-bb16fe72cd5e",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0cf6ad9c-8145-43e8-b796-6ef9567abb75",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.4444444444444444\n",
      "Accuracy: 0.5593406593406594\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        49\n",
      "           1       1.00      1.00      1.00        56\n",
      "\n",
      "    accuracy                           1.00       105\n",
      "   macro avg       1.00      1.00      1.00       105\n",
      "weighted avg       1.00      1.00      1.00       105\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.35      0.44        17\n",
      "           1       0.35      0.60      0.44        10\n",
      "\n",
      "    accuracy                           0.44        27\n",
      "   macro avg       0.48      0.48      0.44        27\n",
      "weighted avg       0.51      0.44      0.44        27\n",
      "\n"
     ]
    }
   ],
   "source": [
    "DecisionTree = DecisionTreeClassifier(max_depth = 10, random_state = 42)\n",
    "DecisionTree.fit(X_train, y_train)\n",
    "print(\"Accuracy:\",accuracy_score(y_test, DecisionTree.predict(X_test)))\n",
    "score = cross_val_score(DecisionTree, X_mfcc_132, y_mfcc_132[0], cv=10)\n",
    "print(f\"Accuracy: {score.mean()}\")\n",
    "print(classification_report(y_train, DecisionTree.predict(X_train)))\n",
    "print(classification_report(y_test, DecisionTree.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df983b34-3be9-445a-a31a-39af6bd3118a",
   "metadata": {},
   "source": [
    "### Bernoulli Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6a39ffda-9f18-4496-a228-3ec24b97d887",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.48148148148148145\n",
      "Accuracy: 0.5912087912087912\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.47      0.56        49\n",
      "           1       0.64      0.82      0.72        56\n",
      "\n",
      "    accuracy                           0.66       105\n",
      "   macro avg       0.67      0.65      0.64       105\n",
      "weighted avg       0.67      0.66      0.65       105\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.41      0.50        17\n",
      "           1       0.38      0.60      0.46        10\n",
      "\n",
      "    accuracy                           0.48        27\n",
      "   macro avg       0.51      0.51      0.48        27\n",
      "weighted avg       0.54      0.48      0.49        27\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Bernoullimodel = BernoulliNB()\n",
    "Bernoullimodel.fit(X_train, y_train)\n",
    "print(\"Accuracy:\",accuracy_score(y_test, Bernoullimodel.predict(X_test)))\n",
    "score = cross_val_score(Bernoullimodel,X_mfcc_132, y_mfcc_132[0], cv=10)\n",
    "print(f\"Accuracy: {score.mean()}\")\n",
    "print(classification_report(y_train, Bernoullimodel.predict(X_train)))\n",
    "print(classification_report(y_test, Bernoullimodel.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9dd505c-8a2a-4556-a69e-c0e7a5eae202",
   "metadata": {},
   "source": [
    "### Bidirectional long short-term memory "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e4609dbb-38bf-4ef6-ac34-f510ca02e9aa",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "4/4 [==============================] - 11s 488ms/step - loss: 0.7001 - accuracy: 0.4476 - val_loss: 0.7020 - val_accuracy: 0.3333\n",
      "Epoch 2/10\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.6859 - accuracy: 0.5429 - val_loss: 0.7222 - val_accuracy: 0.3333\n",
      "Epoch 3/10\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.6849 - accuracy: 0.5429 - val_loss: 0.7467 - val_accuracy: 0.3333\n",
      "Epoch 4/10\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.6859 - accuracy: 0.5429 - val_loss: 0.7502 - val_accuracy: 0.3333\n",
      "Epoch 5/10\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.6829 - accuracy: 0.5524 - val_loss: 0.7408 - val_accuracy: 0.3333\n",
      "Epoch 6/10\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.6812 - accuracy: 0.5619 - val_loss: 0.7107 - val_accuracy: 0.3704\n",
      "Epoch 7/10\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.6752 - accuracy: 0.5905 - val_loss: 0.7020 - val_accuracy: 0.4815\n",
      "Epoch 8/10\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.6717 - accuracy: 0.5905 - val_loss: 0.7008 - val_accuracy: 0.4815\n",
      "Epoch 9/10\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.6680 - accuracy: 0.6000 - val_loss: 0.6977 - val_accuracy: 0.4815\n",
      "Epoch 10/10\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.6653 - accuracy: 0.6095 - val_loss: 0.6925 - val_accuracy: 0.5556\n"
     ]
    }
   ],
   "source": [
    "# Assuming your features are stored in a variable called 'features'\n",
    "# and your labels are stored in a variable called 'labels'\n",
    "\n",
    "# Reshape features to match input shape of model\n",
    "X = np.reshape(X_mfcc_132, (X_mfcc_132.shape[0], 1, X_mfcc_132.shape[1]))\n",
    "\n",
    "# Reshape labels to match output shape of model\n",
    "y = np.reshape(y_mfcc_132, (y_mfcc_132.shape[1],))\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Build and train model\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Bidirectional, LSTM, Dense\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Bidirectional(LSTM(64, return_sequences=True), input_shape=(1, 40)))\n",
    "model.add(Bidirectional(LSTM(32)))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a4310a10-5d40-4899-9021-baa828e04dd5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 4ms/step - loss: 0.6602 - accuracy: 0.6000\n",
      "Train loss: 0.6602362394332886\n",
      "Train accuracy: 0.6000000238418579\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(X_train, y_train)\n",
    "print('Train loss:', loss)\n",
    "print('Train accuracy:', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "26393cfd-3d35-4bb7-a727-a4d7c7c079e6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 41ms/step - loss: 0.6925 - accuracy: 0.5556\n",
      "Test loss: 0.692477822303772\n",
      "Test accuracy: 0.5555555820465088\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print('Test loss:', loss)\n",
    "print('Test accuracy:', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1086d306-46ad-4849-83bd-358e865f82f4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 1s/step\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "y_pred = np.where(y_pred > 0.5, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0f979062-d951-4180-930b-cd6545442fb6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.33      0.50        18\n",
      "           1       0.43      1.00      0.60         9\n",
      "\n",
      "    accuracy                           0.56        27\n",
      "   macro avg       0.71      0.67      0.55        27\n",
      "weighted avg       0.81      0.56      0.53        27\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# print(classification_report(y_train, model.predict(X_train)))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c76b3b04-1978-4e06-8889-e4c1d902ee53",
   "metadata": {},
   "source": [
    "# Actual(132) + Splitted Actual Data(1643)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1caa9d7e-f976-4a6d-92ef-b02d892381cd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_mfcc_1643_new = X_mfcc_1643\n",
    "y_mfcc_1643_new = []\n",
    "\n",
    "for i in y_mfcc_1643:\n",
    "    if i == \"Nonstress\":\n",
    "        y_mfcc_1643_new.append(0)\n",
    "    elif i == \"Stress\":\n",
    "        y_mfcc_1643_new.append(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "071102e5-4d68-4114-be1e-89fdb03d0378",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_mfcc_spactual = list(X_mfcc_132) + list(X_mfcc_1643) # sp - splitted plus\n",
    "y_mfcc_spactual = list(y_mfcc_132[0]) + y_mfcc_1643_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "24ba3b5d-b842-4736-9d23-a2c02c82bf28",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1775"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_mfcc_spactual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "718b8e17-cf61-4d99-b1ec-42b95637d175",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_mfcc_spactual = np.array(X_mfcc_spactual)\n",
    "y_mfcc_spactual = np.array(y_mfcc_spactual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8bb7fcab-b5ba-46bf-8f9d-a7fcae031b34",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1775,)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_mfcc_spactual.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7e9bd91c-c000-4243-9d38-94021d1e294d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "y_mfcc_spactual = y_mfcc_spactual.reshape(1,1775)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "76bc01c0-3afb-4839-9a3b-055f3a0ac697",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(np.array(X_mfcc_spactual), y_mfcc_spactual[0], test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd375826-215e-462f-a215-6d9a46a844ea",
   "metadata": {},
   "source": [
    "### Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "c37f6eb6-a232-41cf-b78b-394f5fee0fd3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.752112676056338\n",
      "Accuracy: 0.5638862438900526\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.75      0.76       724\n",
      "           1       0.75      0.77      0.76       696\n",
      "\n",
      "    accuracy                           0.76      1420\n",
      "   macro avg       0.76      0.76      0.76      1420\n",
      "weighted avg       0.76      0.76      0.76      1420\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.78      0.77       192\n",
      "           1       0.73      0.72      0.73       163\n",
      "\n",
      "    accuracy                           0.75       355\n",
      "   macro avg       0.75      0.75      0.75       355\n",
      "weighted avg       0.75      0.75      0.75       355\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# SVM\n",
    "SVM = SVC(kernel='linear', C=1, random_state=42)\n",
    "SVM.fit(X_train, y_train)\n",
    "print(\"Accuracy:\",accuracy_score(y_test, SVM.predict(X_test)))\n",
    "score = cross_val_score(SVM, X_mfcc_spactual, y_mfcc_spactual[0], cv=10)\n",
    "print(f\"Accuracy: {score.mean()}\")\n",
    "print(classification_report(y_train, SVM.predict(X_train)))\n",
    "print(classification_report(y_test, SVM.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d55c4eb1-281b-4662-abb9-0efde83a3bbc",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "23e9096b-531b-49ac-8940-6ed6d4f68600",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9549295774647887\n",
      "Accuracy: 0.7419348695486575\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       724\n",
      "           1       1.00      1.00      1.00       696\n",
      "\n",
      "    accuracy                           1.00      1420\n",
      "   macro avg       1.00      1.00      1.00      1420\n",
      "weighted avg       1.00      1.00      1.00      1420\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.95      0.96       192\n",
      "           1       0.95      0.96      0.95       163\n",
      "\n",
      "    accuracy                           0.95       355\n",
      "   macro avg       0.95      0.96      0.95       355\n",
      "weighted avg       0.96      0.95      0.95       355\n",
      "\n"
     ]
    }
   ],
   "source": [
    "RandomForest = RandomForestClassifier(oob_score=True, random_state=42)\n",
    "RandomForest.fit(X_train,y_train)\n",
    "print(\"Accuracy:\",accuracy_score(y_test, RandomForest.predict(X_test)))\n",
    "score = cross_val_score(RandomForest, X_mfcc_spactual, y_mfcc_spactual[0], cv=10)\n",
    "print(f\"Accuracy: {score.mean()}\")\n",
    "print(classification_report(y_train, RandomForest.predict(X_train)))\n",
    "print(classification_report(y_test, RandomForest.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0911b639-3234-4e4b-badd-e25ee9328276",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "7493a58b-db9b-4e0c-9da7-0b03f284376b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.819718309859155\n",
      "Accuracy: 0.6376626674284263\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.95      0.96       724\n",
      "           1       0.95      0.98      0.96       696\n",
      "\n",
      "    accuracy                           0.96      1420\n",
      "   macro avg       0.96      0.96      0.96      1420\n",
      "weighted avg       0.96      0.96      0.96      1420\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.84      0.83       192\n",
      "           1       0.81      0.80      0.80       163\n",
      "\n",
      "    accuracy                           0.82       355\n",
      "   macro avg       0.82      0.82      0.82       355\n",
      "weighted avg       0.82      0.82      0.82       355\n",
      "\n"
     ]
    }
   ],
   "source": [
    "DecisionTree = DecisionTreeClassifier(max_depth = 10, random_state = 42)\n",
    "DecisionTree.fit(X_train, y_train)\n",
    "print(\"Accuracy:\",accuracy_score(y_test, DecisionTree.predict(X_test)))\n",
    "score = cross_val_score(DecisionTree, X_mfcc_spactual, y_mfcc_spactual[0], cv=10)\n",
    "print(f\"Accuracy: {score.mean()}\")\n",
    "print(classification_report(y_train, DecisionTree.predict(X_train)))\n",
    "print(classification_report(y_test, DecisionTree.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1479ae13-f57c-4479-ac05-32f0d2bbbca4",
   "metadata": {},
   "source": [
    "### Bernoulli Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "65811abf-148f-4459-9684-486b48f1c814",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6028169014084507\n",
      "Accuracy: 0.5510093315558942\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.48      0.55       724\n",
      "           1       0.58      0.75      0.65       696\n",
      "\n",
      "    accuracy                           0.61      1420\n",
      "   macro avg       0.62      0.61      0.60      1420\n",
      "weighted avg       0.62      0.61      0.60      1420\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.49      0.57       192\n",
      "           1       0.55      0.74      0.63       163\n",
      "\n",
      "    accuracy                           0.60       355\n",
      "   macro avg       0.62      0.61      0.60       355\n",
      "weighted avg       0.62      0.60      0.60       355\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Bernoullimodel = BernoulliNB()\n",
    "Bernoullimodel.fit(X_train, y_train)\n",
    "print(\"Accuracy:\",accuracy_score(y_test, Bernoullimodel.predict(X_test)))\n",
    "score = cross_val_score(Bernoullimodel, X_mfcc_spactual, y_mfcc_spactual[0], cv=10)\n",
    "print(f\"Accuracy: {score.mean()}\")\n",
    "print(classification_report(y_train, Bernoullimodel.predict(X_train)))\n",
    "print(classification_report(y_test, Bernoullimodel.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46dd8f04-c446-46f6-bd6e-aa546b584a8c",
   "metadata": {},
   "source": [
    "### Bidirectional long short-term memory "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "bd8885d5-66ba-4714-8e10-46b0aa82ee8c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "45/45 [==============================] - 21s 47ms/step - loss: 0.6795 - accuracy: 0.5782 - val_loss: 0.6588 - val_accuracy: 0.6197\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - 0s 8ms/step - loss: 0.6317 - accuracy: 0.6472 - val_loss: 0.5960 - val_accuracy: 0.6873\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 0.6073 - accuracy: 0.6641 - val_loss: 0.5697 - val_accuracy: 0.7127\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 0.5711 - accuracy: 0.6901 - val_loss: 0.5539 - val_accuracy: 0.6986\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - 0s 8ms/step - loss: 0.5467 - accuracy: 0.7000 - val_loss: 0.5334 - val_accuracy: 0.7183\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - 0s 8ms/step - loss: 0.5422 - accuracy: 0.7120 - val_loss: 0.5557 - val_accuracy: 0.6986\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - 0s 8ms/step - loss: 0.5422 - accuracy: 0.7092 - val_loss: 0.5376 - val_accuracy: 0.7268\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 0.5100 - accuracy: 0.7296 - val_loss: 0.5015 - val_accuracy: 0.7211\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - 0s 6ms/step - loss: 0.4862 - accuracy: 0.7563 - val_loss: 0.5019 - val_accuracy: 0.7549\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - 0s 8ms/step - loss: 0.4840 - accuracy: 0.7528 - val_loss: 0.4750 - val_accuracy: 0.7577\n"
     ]
    }
   ],
   "source": [
    "X = np.reshape(X_mfcc_spactual, (X_mfcc_spactual.shape[0], 1, X_mfcc_spactual.shape[1]))\n",
    "\n",
    "y = np.reshape(y_mfcc_spactual, (y_mfcc_spactual.shape[1],))\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Bidirectional(LSTM(64, return_sequences=True), input_shape=(1, 40)))\n",
    "model.add(Bidirectional(LSTM(32)))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "3e3ae124-93ae-40bc-90ed-648e6560b12d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - 0s 4ms/step - loss: 0.4513 - accuracy: 0.7761\n",
      "Train loss: 0.4513392448425293\n",
      "Train accuracy: 0.7760563492774963\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(X_train, y_train)\n",
    "print('Train loss:', loss)\n",
    "print('Train accuracy:', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "2d65bd29-4a5d-473f-8495-5e3f4c87402b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4750 - accuracy: 0.7577\n",
      "Test loss: 0.47496888041496277\n",
      "Test accuracy: 0.7577464580535889\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print('Test loss:', loss)\n",
    "print('Test accuracy:', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "004bf244-8289-4a99-b531-0470fe9e7926",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 2s 1ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "y_pred = np.where(y_pred > 0.5, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "f6fc94de-065d-4ee3-8216-ecde506f8fce",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.63      0.73       186\n",
      "           1       0.69      0.89      0.78       169\n",
      "\n",
      "    accuracy                           0.76       355\n",
      "   macro avg       0.78      0.76      0.76       355\n",
      "weighted avg       0.78      0.76      0.75       355\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# print(classification_report(y_train, model.predict(X_train)))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f6210ee-6429-492a-bc3a-668b1c9dc7ee",
   "metadata": {},
   "source": [
    "# Actual(132) + Splitted Augmented Data(2315)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "1c4c0d51-89c0-489d-a996-01beed6f11a0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_A_mfcc_2315_new = X_A_mfcc_2315\n",
    "y_A_mfcc_2315_new = []\n",
    "\n",
    "for i in y_A_mfcc_2315:\n",
    "    if i == \"Nonstress\":\n",
    "        y_A_mfcc_2315_new.append(0)\n",
    "    elif i == \"Stress\":\n",
    "        y_A_mfcc_2315_new.append(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "52262813-42f7-4c6b-89ad-be5af54f49d7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_mfcc_augspactual = list(X_mfcc_132) + list(X_A_mfcc_2315) # sp - splitted plus\n",
    "y_mfcc_augspactual = list(y_mfcc_132[0]) + y_A_mfcc_2315_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "89213a36-6d3b-443a-9e18-5d0ae1405c26",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2447"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_mfcc_augspactual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d17f31af-e166-4a06-a6ef-8c4e711caf4b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_mfcc_augspactual = np.array(X_mfcc_augspactual)\n",
    "y_mfcc_augspactual = np.array(y_mfcc_augspactual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "45c9b3a3-40fc-4d65-b5ee-c60c3e8b468f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2447,)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_mfcc_augspactual.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "891123c6-33bf-46a2-a80e-b0d5f9c36e44",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "y_mfcc_augspactual = y_mfcc_augspactual.reshape(1,2447)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "b5e0bc12-0854-4a12-8c2c-5713ec4836fd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(np.array(X_mfcc_augspactual), y_mfcc_augspactual[0], test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38df6a46-23de-4c9a-93a3-60909ebf0006",
   "metadata": {},
   "source": [
    "### Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "7f5f0073-8258-40f0-a248-087d6bac9b8b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7122448979591837\n",
      "Accuracy: 0.5458380729340917\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.70      0.72       963\n",
      "           1       0.72      0.77      0.75       994\n",
      "\n",
      "    accuracy                           0.73      1957\n",
      "   macro avg       0.73      0.73      0.73      1957\n",
      "weighted avg       0.73      0.73      0.73      1957\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.71      0.70       229\n",
      "           1       0.74      0.72      0.73       261\n",
      "\n",
      "    accuracy                           0.71       490\n",
      "   macro avg       0.71      0.71      0.71       490\n",
      "weighted avg       0.71      0.71      0.71       490\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# SVM\n",
    "SVM = SVC(kernel='linear', C=1, random_state=42)\n",
    "SVM.fit(X_train, y_train)\n",
    "print(\"Accuracy:\",accuracy_score(y_test, SVM.predict(X_test)))\n",
    "score = cross_val_score(SVM, X_mfcc_augspactual, y_mfcc_augspactual[0], cv=10)\n",
    "print(f\"Accuracy: {score.mean()}\")\n",
    "print(classification_report(y_train, SVM.predict(X_train)))\n",
    "print(classification_report(y_test, SVM.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54294e4d-69eb-4257-8107-64e4b73b3f8b",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "6ec8666b-89dc-4494-b8be-73e718af0696",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.926530612244898\n",
      "Accuracy: 0.6427751756440281\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       963\n",
      "           1       1.00      1.00      1.00       994\n",
      "\n",
      "    accuracy                           1.00      1957\n",
      "   macro avg       1.00      1.00      1.00      1957\n",
      "weighted avg       1.00      1.00      1.00      1957\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.91      0.92       229\n",
      "           1       0.92      0.94      0.93       261\n",
      "\n",
      "    accuracy                           0.93       490\n",
      "   macro avg       0.93      0.93      0.93       490\n",
      "weighted avg       0.93      0.93      0.93       490\n",
      "\n"
     ]
    }
   ],
   "source": [
    "RandomForest = RandomForestClassifier(oob_score=True, random_state=42)\n",
    "RandomForest.fit(X_train,y_train)\n",
    "print(\"Accuracy:\",accuracy_score(y_test, RandomForest.predict(X_test)))\n",
    "score = cross_val_score(RandomForest, X_mfcc_augspactual, y_mfcc_augspactual[0], cv=10)\n",
    "print(f\"Accuracy: {score.mean()}\")\n",
    "print(classification_report(y_train, RandomForest.predict(X_train)))\n",
    "print(classification_report(y_test, RandomForest.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c3fdfd1-9b2f-466e-8f4d-cd0996643b52",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "ae526ed9-a26d-4067-ab0f-929fc2720ec3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8122448979591836\n",
      "Accuracy: 0.5929223820675812\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.92      0.94       963\n",
      "           1       0.93      0.97      0.95       994\n",
      "\n",
      "    accuracy                           0.95      1957\n",
      "   macro avg       0.95      0.95      0.95      1957\n",
      "weighted avg       0.95      0.95      0.95      1957\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.77      0.79       229\n",
      "           1       0.81      0.85      0.83       261\n",
      "\n",
      "    accuracy                           0.81       490\n",
      "   macro avg       0.81      0.81      0.81       490\n",
      "weighted avg       0.81      0.81      0.81       490\n",
      "\n"
     ]
    }
   ],
   "source": [
    "DecisionTree = DecisionTreeClassifier(max_depth = 10, random_state = 42)\n",
    "DecisionTree.fit(X_train, y_train)\n",
    "print(\"Accuracy:\",accuracy_score(y_test, DecisionTree.predict(X_test)))\n",
    "score = cross_val_score(DecisionTree, X_mfcc_augspactual, y_mfcc_augspactual[0], cv=10)\n",
    "print(f\"Accuracy: {score.mean()}\")\n",
    "print(classification_report(y_train, DecisionTree.predict(X_train)))\n",
    "print(classification_report(y_test, DecisionTree.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2ee545a-9da7-47ca-892a-34af0f4ce494",
   "metadata": {},
   "source": [
    "### Bernoulli Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "779101ad-85de-440b-9fe2-aa912c95fbb7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6061224489795919\n",
      "Accuracy: 0.49734526597524253\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.49      0.55       963\n",
      "           1       0.59      0.71      0.64       994\n",
      "\n",
      "    accuracy                           0.60      1957\n",
      "   macro avg       0.60      0.60      0.59      1957\n",
      "weighted avg       0.60      0.60      0.60      1957\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.56      0.57       229\n",
      "           1       0.63      0.64      0.64       261\n",
      "\n",
      "    accuracy                           0.61       490\n",
      "   macro avg       0.60      0.60      0.60       490\n",
      "weighted avg       0.61      0.61      0.61       490\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Bernoullimodel = BernoulliNB()\n",
    "Bernoullimodel.fit(X_train, y_train)\n",
    "print(\"Accuracy:\",accuracy_score(y_test, Bernoullimodel.predict(X_test)))\n",
    "score = cross_val_score(Bernoullimodel, X_mfcc_augspactual, y_mfcc_augspactual[0], cv=10)\n",
    "print(f\"Accuracy: {score.mean()}\")\n",
    "print(classification_report(y_train, Bernoullimodel.predict(X_train)))\n",
    "print(classification_report(y_test, Bernoullimodel.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15205d19-8e5d-4558-829c-9efd93814188",
   "metadata": {},
   "source": [
    "### Bidirectional long short-term memory "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "6ce31c06-d097-4837-b191-493bcf5e50d1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "62/62 [==============================] - 9s 28ms/step - loss: 0.6864 - accuracy: 0.5452 - val_loss: 0.6704 - val_accuracy: 0.5755\n",
      "Epoch 2/10\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.6666 - accuracy: 0.5938 - val_loss: 0.6386 - val_accuracy: 0.6653\n",
      "Epoch 3/10\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.6454 - accuracy: 0.6244 - val_loss: 0.6382 - val_accuracy: 0.6531\n",
      "Epoch 4/10\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.6268 - accuracy: 0.6403 - val_loss: 0.5976 - val_accuracy: 0.6878\n",
      "Epoch 5/10\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.6087 - accuracy: 0.6663 - val_loss: 0.5949 - val_accuracy: 0.6816\n",
      "Epoch 6/10\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.5867 - accuracy: 0.6811 - val_loss: 0.5644 - val_accuracy: 0.7122\n",
      "Epoch 7/10\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.5625 - accuracy: 0.7046 - val_loss: 0.5220 - val_accuracy: 0.7429\n",
      "Epoch 8/10\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 0.5577 - accuracy: 0.7067 - val_loss: 0.5150 - val_accuracy: 0.7367\n",
      "Epoch 9/10\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.5178 - accuracy: 0.7414 - val_loss: 0.5091 - val_accuracy: 0.7306\n",
      "Epoch 10/10\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.5187 - accuracy: 0.7368 - val_loss: 0.4974 - val_accuracy: 0.7551\n"
     ]
    }
   ],
   "source": [
    "X = np.reshape(X_mfcc_augspactual, (X_mfcc_augspactual.shape[0], 1, X_mfcc_augspactual.shape[1]))\n",
    "\n",
    "y = np.reshape(y_mfcc_augspactual, (y_mfcc_augspactual.shape[1],))\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Bidirectional(LSTM(64, return_sequences=True), input_shape=(1, 40)))\n",
    "model.add(Bidirectional(LSTM(32)))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "063a11ee-9780-41b5-95c5-f5a6fbbd883a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62/62 [==============================] - 1s 3ms/step - loss: 0.4913 - accuracy: 0.7655\n",
      "Train loss: 0.4912759065628052\n",
      "Train accuracy: 0.7654573321342468\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(X_train, y_train)\n",
    "print('Train loss:', loss)\n",
    "print('Train accuracy:', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "1b55d6c3-707d-48b4-b49c-d45a23d015a2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4974 - accuracy: 0.7551\n",
      "Test loss: 0.4974401295185089\n",
      "Test accuracy: 0.7551020383834839\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print('Test loss:', loss)\n",
    "print('Test accuracy:', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "db66efab-f794-40a4-8746-38766d2a2144",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 3s 3ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "y_pred = np.where(y_pred > 0.5, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "8874aafb-921b-4b58-8c22-17ed6e2657e9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.66      0.73       243\n",
      "           1       0.72      0.85      0.78       247\n",
      "\n",
      "    accuracy                           0.76       490\n",
      "   macro avg       0.76      0.75      0.75       490\n",
      "weighted avg       0.76      0.76      0.75       490\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# print(classification_report(y_train, model.predict(X_train)))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6f6dfeb-f4ba-452c-841e-911abef67477",
   "metadata": {},
   "source": [
    "# Actual(132) + Augmented(Noise Added Data)(132)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "39abd0c1-14e2-4ab0-844a-ebb526be734a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "y_A_mfcc_132_new = []\n",
    "\n",
    "for i in y_A_mfcc_132:\n",
    "    if i == \"Nonstress\":\n",
    "        y_A_mfcc_132_new.append(0)\n",
    "    elif i == \"Stress\":\n",
    "        y_A_mfcc_132_new.append(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "d9fb2577-231e-41b8-bae5-b1198db4cf33",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_mfcc_264 = list(X_mfcc_132) + list(X_A_mfcc_132) # sp - splitted plus\n",
    "y_mfcc_264 = list(y_mfcc_132[0]) + y_A_mfcc_132_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "cb44b731-eba2-4f2d-b4c4-5e6b01c86562",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "264"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_mfcc_264)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "011a45a1-745a-44cd-a69b-aa9b331b0c6b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_mfcc_264 = np.array(X_mfcc_264)\n",
    "y_mfcc_264 = np.array(y_mfcc_264)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "e77cd1b5-c09f-4e47-8d51-a4849e9e0da2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(264,)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_mfcc_264.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "1be8b1c1-9fc7-4598-aabf-3152b4f4d165",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "y_mfcc_264 = y_mfcc_264.reshape(1,264)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "66f752a3-da48-4307-890d-a6d561efd4a5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(np.array(X_mfcc_264), y_mfcc_264[0], test_size=0.2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fe4283b-ae83-4d14-94d0-d76acbc9b95d",
   "metadata": {},
   "source": [
    "### Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "a34ccb8c-116c-422c-9bef-e464917ebd02",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7358490566037735\n",
      "Accuracy: 0.6357549857549858\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.70      0.76       108\n",
      "           1       0.73      0.83      0.78       103\n",
      "\n",
      "    accuracy                           0.77       211\n",
      "   macro avg       0.77      0.77      0.77       211\n",
      "weighted avg       0.77      0.77      0.77       211\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.67      0.70        24\n",
      "           1       0.74      0.79      0.77        29\n",
      "\n",
      "    accuracy                           0.74        53\n",
      "   macro avg       0.73      0.73      0.73        53\n",
      "weighted avg       0.74      0.74      0.73        53\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# SVM\n",
    "SVM = SVC(kernel='linear', C=1, random_state=42)\n",
    "SVM.fit(X_train, y_train)\n",
    "print(\"Accuracy:\",accuracy_score(y_test, SVM.predict(X_test)))\n",
    "score = cross_val_score(SVM, X_mfcc_264, y_mfcc_264[0], cv=10)\n",
    "\n",
    "print(f\"Accuracy: {score.mean()}\")\n",
    "print(classification_report(y_train, SVM.predict(X_train)))\n",
    "print(classification_report(y_test, SVM.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23176aa3-2216-4acd-b89d-d08371ac1c98",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "ce7eb99c-0b5a-4a0e-b65d-165f254e0f5d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5471698113207547\n",
      "Accuracy: 0.7115384615384616\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       108\n",
      "           1       1.00      1.00      1.00       103\n",
      "\n",
      "    accuracy                           1.00       211\n",
      "   macro avg       1.00      1.00      1.00       211\n",
      "weighted avg       1.00      1.00      1.00       211\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.71      0.59        24\n",
      "           1       0.63      0.41      0.50        29\n",
      "\n",
      "    accuracy                           0.55        53\n",
      "   macro avg       0.57      0.56      0.54        53\n",
      "weighted avg       0.57      0.55      0.54        53\n",
      "\n"
     ]
    }
   ],
   "source": [
    "RandomForest = RandomForestClassifier(oob_score=True, random_state=42)\n",
    "RandomForest.fit(X_train,y_train)\n",
    "print(\"Accuracy:\",accuracy_score(y_test, RandomForest.predict(X_test)))\n",
    "score = cross_val_score(RandomForest, X_mfcc_264, y_mfcc_264[0], cv=10)\n",
    "print(f\"Accuracy: {score.mean()}\")\n",
    "print(classification_report(y_train, RandomForest.predict(X_train)))\n",
    "print(classification_report(y_test, RandomForest.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40b7919a-6798-4c8f-92f6-16021e88e202",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "21757bb1-ace3-4cd9-b707-1c5a7f73314b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5660377358490566\n",
      "Accuracy: 0.631908831908832\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.97      0.99       108\n",
      "           1       0.97      1.00      0.99       103\n",
      "\n",
      "    accuracy                           0.99       211\n",
      "   macro avg       0.99      0.99      0.99       211\n",
      "weighted avg       0.99      0.99      0.99       211\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.52      0.46      0.49        24\n",
      "           1       0.59      0.66      0.62        29\n",
      "\n",
      "    accuracy                           0.57        53\n",
      "   macro avg       0.56      0.56      0.56        53\n",
      "weighted avg       0.56      0.57      0.56        53\n",
      "\n"
     ]
    }
   ],
   "source": [
    "DecisionTree = DecisionTreeClassifier(max_depth = 10, random_state = 42)\n",
    "DecisionTree.fit(X_train, y_train)\n",
    "print(\"Accuracy:\",accuracy_score(y_test, DecisionTree.predict(X_test)))\n",
    "score = cross_val_score(DecisionTree, X_mfcc_264, y_mfcc_264[0], cv=10)\n",
    "print(f\"Accuracy: {score.mean()}\")\n",
    "print(classification_report(y_train, DecisionTree.predict(X_train)))\n",
    "print(classification_report(y_test, DecisionTree.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fc99655-2bb7-4b1a-abfa-e9309a4adde9",
   "metadata": {},
   "source": [
    "### Bernoulli Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "06dda14b-db4b-4d5b-ae1b-564161e3afc6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5471698113207547\n",
      "Accuracy: 0.5596866096866095\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.50      0.58       108\n",
      "           1       0.59      0.76      0.66       103\n",
      "\n",
      "    accuracy                           0.63       211\n",
      "   macro avg       0.64      0.63      0.62       211\n",
      "weighted avg       0.64      0.63      0.62       211\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.62      0.56        24\n",
      "           1       0.61      0.48      0.54        29\n",
      "\n",
      "    accuracy                           0.55        53\n",
      "   macro avg       0.55      0.55      0.55        53\n",
      "weighted avg       0.56      0.55      0.55        53\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Bernoullimodel = BernoulliNB()\n",
    "Bernoullimodel.fit(X_train, y_train)\n",
    "print(\"Accuracy:\",accuracy_score(y_test, Bernoullimodel.predict(X_test)))\n",
    "score = cross_val_score(Bernoullimodel, X_mfcc_264, y_mfcc_264[0], cv=10)\n",
    "print(f\"Accuracy: {score.mean()}\")\n",
    "print(classification_report(y_train, Bernoullimodel.predict(X_train)))\n",
    "print(classification_report(y_test, Bernoullimodel.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb37cc6a-4c2b-4413-9743-386b19dab749",
   "metadata": {},
   "source": [
    "### Bidirectional long short-term memory "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "7e4515fa-83fb-4614-a896-176dd53110f7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "7/7 [==============================] - 13s 247ms/step - loss: 0.7002 - accuracy: 0.4502 - val_loss: 0.6922 - val_accuracy: 0.4906\n",
      "Epoch 2/10\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.6894 - accuracy: 0.5403 - val_loss: 0.6872 - val_accuracy: 0.6038\n",
      "Epoch 3/10\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.6860 - accuracy: 0.5924 - val_loss: 0.6847 - val_accuracy: 0.5660\n",
      "Epoch 4/10\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.6810 - accuracy: 0.6256 - val_loss: 0.6788 - val_accuracy: 0.6604\n",
      "Epoch 5/10\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.6769 - accuracy: 0.6066 - val_loss: 0.6772 - val_accuracy: 0.5472\n",
      "Epoch 6/10\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.6697 - accuracy: 0.6351 - val_loss: 0.6631 - val_accuracy: 0.6415\n",
      "Epoch 7/10\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.6597 - accuracy: 0.6351 - val_loss: 0.6607 - val_accuracy: 0.5660\n",
      "Epoch 8/10\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.6545 - accuracy: 0.6256 - val_loss: 0.6420 - val_accuracy: 0.6604\n",
      "Epoch 9/10\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.6490 - accuracy: 0.6493 - val_loss: 0.6443 - val_accuracy: 0.6038\n",
      "Epoch 10/10\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.6447 - accuracy: 0.6588 - val_loss: 0.6411 - val_accuracy: 0.6604\n"
     ]
    }
   ],
   "source": [
    "X = np.reshape(X_mfcc_264, (X_mfcc_264.shape[0], 1, X_mfcc_264.shape[1]))\n",
    "\n",
    "y = np.reshape(y_mfcc_264, (y_mfcc_264.shape[1],))\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Bidirectional(LSTM(64, return_sequences=True), input_shape=(1, 40)))\n",
    "model.add(Bidirectional(LSTM(32)))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "11f11788-8bed-4c2c-829b-ae9849a6e351",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6347 - accuracy: 0.6588\n",
      "Train loss: 0.6346639394760132\n",
      "Train accuracy: 0.6587677597999573\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(X_train, y_train)\n",
    "print('Train loss:', loss)\n",
    "print('Train accuracy:', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "2a5f8e4b-d683-42f9-a9be-89c4ef8ecf0a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6411 - accuracy: 0.6604\n",
      "Test loss: 0.6410793662071228\n",
      "Test accuracy: 0.6603773832321167\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print('Test loss:', loss)\n",
    "print('Test accuracy:', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "915bc41d-9ff1-467a-9b87-93334469b38d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 2s 4ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "y_pred = np.where(y_pred > 0.5, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "392d9841-03dc-4147-a2e1-9b78938276c4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.59      0.64        27\n",
      "           1       0.63      0.73      0.68        26\n",
      "\n",
      "    accuracy                           0.66        53\n",
      "   macro avg       0.66      0.66      0.66        53\n",
      "weighted avg       0.67      0.66      0.66        53\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# print(classification_report(y_train, model.predict(X_train)))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dfd3017-aa83-4c23-8c56-c42afc91d585",
   "metadata": {},
   "source": [
    "# Actual(132) + Augmented Noise Added(132) + Whole Splitted(3958)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "ce5a9e1a-59df-490d-96b0-5d399d083282",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "y_A_mfcc_2315_new = []\n",
    "\n",
    "for i in y_A_mfcc_2315:\n",
    "    if i == \"Nonstress\":\n",
    "        y_A_mfcc_2315_new.append(0)\n",
    "    elif i == \"Stress\":\n",
    "        y_A_mfcc_2315_new.append(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "895798c5-9a12-4e82-97e2-65ec699f3b45",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_mfcc_spaugactual = list(X_mfcc_264) + list(X_mfcc_1643) + list(X_A_mfcc_2315) # sp - splitted plus\n",
    "y_mfcc_spaugactual = list(y_mfcc_264[0]) + list(y_mfcc_1643_new) + list(y_A_mfcc_2315_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "a96bf606-7be8-4c63-819c-bcb4069b97a1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_mfcc_spaugactual = np.array(X_mfcc_spaugactual)\n",
    "y_mfcc_spaugactual = np.array(y_mfcc_spaugactual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "e8c1dae0-190a-44b3-8b86-b885083b4e1b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "y_mfcc_spaugactual = y_mfcc_spaugactual.reshape(1,4222)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "80575c3d-1660-49a6-88cd-418b48a93be2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(np.array(X_mfcc_spaugactual), y_mfcc_spaugactual[0], test_size=0.2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa5df7dd-1cb8-4115-b7ae-9b3054588dbd",
   "metadata": {},
   "source": [
    "### Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "45676fc2-b000-4e7e-a03c-fd195135d9a1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7159763313609467\n",
      "Accuracy: 0.6110590120220049\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.69      0.70      1686\n",
      "           1       0.70      0.74      0.72      1691\n",
      "\n",
      "    accuracy                           0.71      3377\n",
      "   macro avg       0.71      0.71      0.71      3377\n",
      "weighted avg       0.71      0.71      0.71      3377\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.67      0.70       422\n",
      "           1       0.70      0.76      0.73       423\n",
      "\n",
      "    accuracy                           0.72       845\n",
      "   macro avg       0.72      0.72      0.72       845\n",
      "weighted avg       0.72      0.72      0.72       845\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# SVM\n",
    "SVM = SVC(kernel='linear', C=1, random_state=42)\n",
    "SVM.fit(X_train, y_train)\n",
    "print(\"Accuracy:\",accuracy_score(y_test, SVM.predict(X_test)))\n",
    "score = cross_val_score(SVM, X_mfcc_spaugactual, y_mfcc_spaugactual[0], cv=10)\n",
    "\n",
    "print(f\"Accuracy: {score.mean()}\")\n",
    "print(classification_report(y_train, SVM.predict(X_train)))\n",
    "print(classification_report(y_test, SVM.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b65c689b-a5e3-4fee-80e8-e7af6299755f",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "8b2b1f41-2bae-47a4-bf3f-8d0ad6ced75f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9479289940828403\n",
      "Accuracy: 0.8097744613626432\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1686\n",
      "           1       1.00      1.00      1.00      1691\n",
      "\n",
      "    accuracy                           1.00      3377\n",
      "   macro avg       1.00      1.00      1.00      3377\n",
      "weighted avg       1.00      1.00      1.00      3377\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.94      0.95       422\n",
      "           1       0.94      0.96      0.95       423\n",
      "\n",
      "    accuracy                           0.95       845\n",
      "   macro avg       0.95      0.95      0.95       845\n",
      "weighted avg       0.95      0.95      0.95       845\n",
      "\n"
     ]
    }
   ],
   "source": [
    "RandomForest = RandomForestClassifier(oob_score=True, random_state=42)\n",
    "RandomForest.fit(X_train,y_train)\n",
    "print(\"Accuracy:\",accuracy_score(y_test, RandomForest.predict(X_test)))\n",
    "score = cross_val_score(RandomForest, X_mfcc_spaugactual, y_mfcc_spaugactual[0], cv=10)\n",
    "print(f\"Accuracy: {score.mean()}\")\n",
    "print(classification_report(y_train, RandomForest.predict(X_train)))\n",
    "print(classification_report(y_test, RandomForest.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91005afa-673a-43fc-969f-69ae5765851d",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "c06b82a3-da53-4dd0-8376-503b495a0a37",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8153846153846154\n",
      "Accuracy: 0.6695702105251364\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.95      0.94      1686\n",
      "           1       0.95      0.94      0.94      1691\n",
      "\n",
      "    accuracy                           0.94      3377\n",
      "   macro avg       0.94      0.94      0.94      3377\n",
      "weighted avg       0.94      0.94      0.94      3377\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.83      0.82       422\n",
      "           1       0.82      0.80      0.81       423\n",
      "\n",
      "    accuracy                           0.82       845\n",
      "   macro avg       0.82      0.82      0.82       845\n",
      "weighted avg       0.82      0.82      0.82       845\n",
      "\n"
     ]
    }
   ],
   "source": [
    "DecisionTree = DecisionTreeClassifier(max_depth = 10, random_state = 42)\n",
    "DecisionTree.fit(X_train, y_train)\n",
    "print(\"Accuracy:\",accuracy_score(y_test, DecisionTree.predict(X_test)))\n",
    "score = cross_val_score(DecisionTree, X_mfcc_spaugactual, y_mfcc_spaugactual[0], cv=10)\n",
    "print(f\"Accuracy: {score.mean()}\")\n",
    "print(classification_report(y_train, DecisionTree.predict(X_train)))\n",
    "print(classification_report(y_test, DecisionTree.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a479551-b263-4786-b1f9-f22b07cc41d0",
   "metadata": {},
   "source": [
    "### Bernoulli Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "90c3a001-8d2c-4990-b3ad-fb9ce4b0fa33",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5668639053254438\n",
      "Accuracy: 0.5386082260540263\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.49      0.54      1686\n",
      "           1       0.57      0.66      0.61      1691\n",
      "\n",
      "    accuracy                           0.58      3377\n",
      "   macro avg       0.58      0.58      0.57      3377\n",
      "weighted avg       0.58      0.58      0.57      3377\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.49      0.53       422\n",
      "           1       0.56      0.65      0.60       423\n",
      "\n",
      "    accuracy                           0.57       845\n",
      "   macro avg       0.57      0.57      0.56       845\n",
      "weighted avg       0.57      0.57      0.56       845\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Bernoullimodel = BernoulliNB()\n",
    "Bernoullimodel.fit(X_train, y_train)\n",
    "print(\"Accuracy:\",accuracy_score(y_test, Bernoullimodel.predict(X_test)))\n",
    "score = cross_val_score(Bernoullimodel, X_mfcc_spaugactual, y_mfcc_spaugactual[0], cv=10)\n",
    "print(f\"Accuracy: {score.mean()}\")\n",
    "print(classification_report(y_train, Bernoullimodel.predict(X_train)))\n",
    "print(classification_report(y_test, Bernoullimodel.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "978bb830-1d88-472a-892a-350dc653c84d",
   "metadata": {},
   "source": [
    "### Bidirectional long short-term memory "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "a3925931-8b9c-4d1c-9a22-7a9fc014367c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "106/106 [==============================] - 14s 66ms/step - loss: 0.6691 - accuracy: 0.5908 - val_loss: 0.6462 - val_accuracy: 0.6130\n",
      "Epoch 2/10\n",
      "106/106 [==============================] - 1s 5ms/step - loss: 0.6249 - accuracy: 0.6553 - val_loss: 0.6484 - val_accuracy: 0.5976\n",
      "Epoch 3/10\n",
      "106/106 [==============================] - 1s 5ms/step - loss: 0.5873 - accuracy: 0.6755 - val_loss: 0.5967 - val_accuracy: 0.6888\n",
      "Epoch 4/10\n",
      "106/106 [==============================] - 1s 5ms/step - loss: 0.5600 - accuracy: 0.6935 - val_loss: 0.5666 - val_accuracy: 0.6994\n",
      "Epoch 5/10\n",
      "106/106 [==============================] - 1s 5ms/step - loss: 0.5240 - accuracy: 0.7202 - val_loss: 0.5227 - val_accuracy: 0.7148\n",
      "Epoch 6/10\n",
      "106/106 [==============================] - 1s 5ms/step - loss: 0.4962 - accuracy: 0.7409 - val_loss: 0.5093 - val_accuracy: 0.7361\n",
      "Epoch 7/10\n",
      "106/106 [==============================] - 1s 5ms/step - loss: 0.4778 - accuracy: 0.7560 - val_loss: 0.4821 - val_accuracy: 0.7609\n",
      "Epoch 8/10\n",
      "106/106 [==============================] - 1s 6ms/step - loss: 0.4605 - accuracy: 0.7655 - val_loss: 0.4840 - val_accuracy: 0.7586\n",
      "Epoch 9/10\n",
      "106/106 [==============================] - 1s 5ms/step - loss: 0.4339 - accuracy: 0.7903 - val_loss: 0.4518 - val_accuracy: 0.7751\n",
      "Epoch 10/10\n",
      "106/106 [==============================] - 1s 5ms/step - loss: 0.4172 - accuracy: 0.7936 - val_loss: 0.4337 - val_accuracy: 0.7751\n"
     ]
    }
   ],
   "source": [
    "X = np.reshape(X_mfcc_spaugactual, (X_mfcc_spaugactual.shape[0], 1, X_mfcc_spaugactual.shape[1]))\n",
    "\n",
    "y = np.reshape(y_mfcc_spaugactual, (y_mfcc_spaugactual.shape[1],))\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Bidirectional(LSTM(64, return_sequences=True), input_shape=(1, 40)))\n",
    "model.add(Bidirectional(LSTM(32)))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "59a23bb5-48c5-4144-aa64-027ea0a121ad",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "106/106 [==============================] - 0s 2ms/step - loss: 0.4056 - accuracy: 0.8117\n",
      "Train loss: 0.40560317039489746\n",
      "Train accuracy: 0.8116671442985535\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(X_train, y_train)\n",
    "print('Train loss:', loss)\n",
    "print('Train accuracy:', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "8fcb6c66-6a59-4236-9f30-00ee40bee458",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27/27 [==============================] - 0s 3ms/step - loss: 0.4337 - accuracy: 0.7751\n",
      "Test loss: 0.4336513876914978\n",
      "Test accuracy: 0.7751479148864746\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print('Test loss:', loss)\n",
    "print('Test accuracy:', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "5337b3e9-fbfd-4f2f-972d-c441a93c6cdf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27/27 [==============================] - 2s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "y_pred = np.where(y_pred > 0.5, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "a3f9fb52-5662-4370-be4d-52bf8e64789f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.84      0.79       431\n",
      "           1       0.81      0.70      0.75       414\n",
      "\n",
      "    accuracy                           0.78       845\n",
      "   macro avg       0.78      0.77      0.77       845\n",
      "weighted avg       0.78      0.78      0.77       845\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# print(classification_report(y_train, model.predict(X_train)))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5b4a949-d906-4ba0-a7b4-e1d81cf0a533",
   "metadata": {},
   "source": [
    "# Actual(132) + Augmented(132) + Splitted Actual(1643)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "21831825-8336-4b0a-9bdd-50bdd4d57376",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_mfcc_spaugactual1 = list(X_mfcc_264) + list(X_mfcc_1643) \n",
    "y_mfcc_spaugactual1 = list(y_mfcc_264[0]) + list(y_mfcc_1643_new) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "7c078a93-3753-4961-98a0-265978abd07e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_mfcc_spaugactual1 = np.array(X_mfcc_spaugactual1)\n",
    "y_mfcc_spaugactual1 = np.array(y_mfcc_spaugactual1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "398ef47b-814e-40ff-8a18-2fe823e5fe61",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_mfcc_spaugactual1 = y_mfcc_spaugactual1.reshape(1,1907)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "1aff4b6d-5b4d-4044-ac12-75f23608b504",
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.random.seed(40)\n",
    "X_train, X_test, y_train, y_test = train_test_split(np.array(X_mfcc_spaugactual1), y_mfcc_spaugactual1[0], test_size=0.2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d3ac4b4-f61b-4f3c-a3fe-f846d7d22eec",
   "metadata": {},
   "source": [
    "### Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "0ee19cf3-f28b-44dc-a6cc-7a55ba673edb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7277486910994765\n",
      "Accuracy: 0.548793055938275\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.75      0.75       781\n",
      "           1       0.73      0.74      0.74       744\n",
      "\n",
      "    accuracy                           0.74      1525\n",
      "   macro avg       0.74      0.74      0.74      1525\n",
      "weighted avg       0.74      0.74      0.74      1525\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.71      0.73       201\n",
      "           1       0.70      0.75      0.72       181\n",
      "\n",
      "    accuracy                           0.73       382\n",
      "   macro avg       0.73      0.73      0.73       382\n",
      "weighted avg       0.73      0.73      0.73       382\n",
      "\n"
     ]
    }
   ],
   "source": [
    "SVM = SVC(kernel='linear', C=1, random_state=42)\n",
    "SVM.fit(X_train, y_train)\n",
    "print(\"Accuracy:\",accuracy_score(y_test, SVM.predict(X_test)))\n",
    "score = cross_val_score(SVM, X_mfcc_spaugactual1, y_mfcc_spaugactual1[0], cv=10)\n",
    "\n",
    "print(f\"Accuracy: {score.mean()}\")\n",
    "print(classification_report(y_train, SVM.predict(X_train)))\n",
    "print(classification_report(y_test, SVM.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1506070-cda4-4ffa-9f1d-cec3f04cccbe",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "8db378d3-1f40-4457-8249-ea5f8c5f38cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.93717277486911\n",
      "Accuracy: 0.7534224304216037\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       781\n",
      "           1       1.00      1.00      1.00       744\n",
      "\n",
      "    accuracy                           1.00      1525\n",
      "   macro avg       1.00      1.00      1.00      1525\n",
      "weighted avg       1.00      1.00      1.00      1525\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.93      0.94       201\n",
      "           1       0.92      0.95      0.93       181\n",
      "\n",
      "    accuracy                           0.94       382\n",
      "   macro avg       0.94      0.94      0.94       382\n",
      "weighted avg       0.94      0.94      0.94       382\n",
      "\n"
     ]
    }
   ],
   "source": [
    "RandomForest = RandomForestClassifier(oob_score=True, random_state=42)\n",
    "RandomForest.fit(X_train,y_train)\n",
    "print(\"Accuracy:\",accuracy_score(y_test, RandomForest.predict(X_test)))\n",
    "score = cross_val_score(RandomForest, X_mfcc_spaugactual1, y_mfcc_spaugactual1[0], cv=10)\n",
    "print(f\"Accuracy: {score.mean()}\")\n",
    "print(classification_report(y_train, RandomForest.predict(X_train)))\n",
    "print(classification_report(y_test, RandomForest.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66baffb3-8dd2-401e-9365-78cb1d32e716",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "ce65a124-997c-44e0-91f6-dcbdbff5f342",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.856020942408377\n",
      "Accuracy: 0.6228244695508405\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.96      0.96       781\n",
      "           1       0.96      0.96      0.96       744\n",
      "\n",
      "    accuracy                           0.96      1525\n",
      "   macro avg       0.96      0.96      0.96      1525\n",
      "weighted avg       0.96      0.96      0.96      1525\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.89      0.87       201\n",
      "           1       0.87      0.82      0.84       181\n",
      "\n",
      "    accuracy                           0.86       382\n",
      "   macro avg       0.86      0.85      0.86       382\n",
      "weighted avg       0.86      0.86      0.86       382\n",
      "\n"
     ]
    }
   ],
   "source": [
    "DecisionTree = DecisionTreeClassifier(max_depth = 10, random_state = 42)\n",
    "DecisionTree.fit(X_train, y_train)\n",
    "print(\"Accuracy:\",accuracy_score(y_test, DecisionTree.predict(X_test)))\n",
    "score = cross_val_score(DecisionTree, X_mfcc_spaugactual1, y_mfcc_spaugactual1[0], cv=10)\n",
    "print(f\"Accuracy: {score.mean()}\")\n",
    "print(classification_report(y_train, DecisionTree.predict(X_train)))\n",
    "print(classification_report(y_test, DecisionTree.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cabf4f5a-5230-4f55-81c6-c1bacf9a17ae",
   "metadata": {},
   "source": [
    "### Bernoulli Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "9472c706-64a9-4de5-b7dd-43b61e42ac52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5942408376963351\n",
      "Accuracy: 0.5726012675668228\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.48      0.56       781\n",
      "           1       0.58      0.74      0.65       744\n",
      "\n",
      "    accuracy                           0.61      1525\n",
      "   macro avg       0.62      0.61      0.60      1525\n",
      "weighted avg       0.62      0.61      0.60      1525\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.47      0.55       201\n",
      "           1       0.55      0.73      0.63       181\n",
      "\n",
      "    accuracy                           0.59       382\n",
      "   macro avg       0.61      0.60      0.59       382\n",
      "weighted avg       0.61      0.59      0.59       382\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Bernoullimodel = BernoulliNB()\n",
    "Bernoullimodel.fit(X_train, y_train)\n",
    "print(\"Accuracy:\",accuracy_score(y_test, Bernoullimodel.predict(X_test)))\n",
    "score = cross_val_score(Bernoullimodel, X_mfcc_spaugactual1, y_mfcc_spaugactual1[0], cv=10)\n",
    "print(f\"Accuracy: {score.mean()}\")\n",
    "print(classification_report(y_train, Bernoullimodel.predict(X_train)))\n",
    "print(classification_report(y_test, Bernoullimodel.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2e32465-4471-4b81-b3e9-d589af43ceff",
   "metadata": {},
   "source": [
    "### Bidirectional long short-term memory "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "677b279b-c677-405f-81ec-1e70d221f235",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "48/48 [==============================] - 11s 40ms/step - loss: 0.6731 - accuracy: 0.5882 - val_loss: 0.6772 - val_accuracy: 0.5157\n",
      "Epoch 2/10\n",
      "48/48 [==============================] - 0s 6ms/step - loss: 0.6326 - accuracy: 0.6426 - val_loss: 0.6128 - val_accuracy: 0.6937\n",
      "Epoch 3/10\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 0.6160 - accuracy: 0.6531 - val_loss: 0.6035 - val_accuracy: 0.6806\n",
      "Epoch 4/10\n",
      "48/48 [==============================] - 0s 6ms/step - loss: 0.5978 - accuracy: 0.6748 - val_loss: 0.5941 - val_accuracy: 0.6806\n",
      "Epoch 5/10\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 0.5919 - accuracy: 0.6807 - val_loss: 0.5791 - val_accuracy: 0.6780\n",
      "Epoch 6/10\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 0.5572 - accuracy: 0.6931 - val_loss: 0.6134 - val_accuracy: 0.6414\n",
      "Epoch 7/10\n",
      "48/48 [==============================] - 0s 6ms/step - loss: 0.5553 - accuracy: 0.6997 - val_loss: 0.5407 - val_accuracy: 0.6937\n",
      "Epoch 8/10\n",
      "48/48 [==============================] - 0s 6ms/step - loss: 0.5333 - accuracy: 0.7056 - val_loss: 0.5295 - val_accuracy: 0.7016\n",
      "Epoch 9/10\n",
      "48/48 [==============================] - 0s 7ms/step - loss: 0.5113 - accuracy: 0.7325 - val_loss: 0.5008 - val_accuracy: 0.7120\n",
      "Epoch 10/10\n",
      "48/48 [==============================] - 0s 6ms/step - loss: 0.4936 - accuracy: 0.7436 - val_loss: 0.4924 - val_accuracy: 0.7408\n"
     ]
    }
   ],
   "source": [
    "X = np.reshape(X_mfcc_spaugactual1, (X_mfcc_spaugactual1.shape[0], 1, X_mfcc_spaugactual.shape[1]))\n",
    "\n",
    "y = np.reshape(y_mfcc_spaugactual1, (y_mfcc_spaugactual1.shape[1],))\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Bidirectional(LSTM(64, return_sequences=True), input_shape=(1, 40)))\n",
    "model.add(Bidirectional(LSTM(32)))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "e0a54b1c-462d-4d89-b77c-691e4b5374f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48/48 [==============================] - 0s 3ms/step - loss: 0.4689 - accuracy: 0.7685\n",
      "Train loss: 0.46887847781181335\n",
      "Train accuracy: 0.7685245871543884\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(X_train, y_train)\n",
    "print('Train loss:', loss)\n",
    "print('Train accuracy:', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "0f3e3acd-515d-4710-b211-4e6014574a0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4924 - accuracy: 0.7408\n",
      "Test loss: 0.49238163232803345\n",
      "Test accuracy: 0.7408376932144165\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print('Test loss:', loss)\n",
    "print('Test accuracy:', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "7b18841b-69d4-44fe-8d16-c904cc56cf37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 1s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "y_pred = np.where(y_pred > 0.5, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "2db5d682-5c26-4b0d-93f7-5d70f211c6ee",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.66      0.71       184\n",
      "           1       0.72      0.81      0.76       198\n",
      "\n",
      "    accuracy                           0.74       382\n",
      "   macro avg       0.74      0.74      0.74       382\n",
      "weighted avg       0.74      0.74      0.74       382\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# print(classification_report(y_train, model.predict(X_train)))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
